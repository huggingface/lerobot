# =============================================================================
# SETUP
# =============================================================================
# Activate conda environment
conda activate lerobot

# Set USB permissions (run every time after reboot or USB reconnect)
sudo chmod 666 /dev/ttyACM0 /dev/ttyACM1 /dev/ttyACM2

# =============================================================================
# GIT WORKFLOW - SYNC WITH GITHUB REPO
# =============================================================================
# Navigate to lerobot directory
cd /home/jetson/lerobot

# ONE-TIME SETUP (if not already done):
# git config --global user.name "ImpurestTadpole"
# git config --global user.email "your-email@example.com"
# git remote add origin https://github.com/ImpurestTadpole/lerobot.git

# UPDATE FROM GITHUB (pull latest changes):
# First, check if you have uncommitted changes:
git status

# OPTION A: Commit your local changes first, then pull:
git add .
git commit -m "Save local changes before pulling"
git config pull.rebase false  # Set merge strategy (one-time)
git pull origin main          # Merge remote changes into local

# OPTION B: Stash your changes, pull, then reapply:
git stash                      # Temporarily save your changes
git config pull.rebase false  # Set merge strategy (one-time)
git pull origin main          # Merge remote changes into local
git stash pop                 # Reapply your stashed changes

# If merge conflicts occur after pull:
# 1. Resolve conflicts in the files git lists (look for <<<<<<< markers)
# 2. git add .
# 3. git commit -m "Resolve merge conflicts"
# 4. git push origin main

# PUSH LOCAL CHANGES TO GITHUB:
git add .                     # Stage all changes
git commit -m "Your commit message here"
git push origin main          # Push to GitHub

# CHECK STATUS:
git status                    # See what files have changed
git log --oneline            # See commit history
git remote -v                 # Verify remote URL

# =============================================================================
# TELEOPERATION
# =============================================================================
# ON JETSON:
lerobot-teleoperate \
    --robot.type=xlerobot \
    --teleop.type=xlerobot_vr \
    --display_data=true

# =============================================================================
# REMOTE VISUALIZATION (ON EXTERNAL PC)
# =============================================================================

# OPTION 1: Direct connection (recommended - best performance)
rerun --serve-web --web-viewer-port 9090 --connect "rerun+http://192.168.0.104:9876/proxy"

# OPTION 2: Via SSH tunnel
# Terminal 1:
ssh -L 9876:localhost:9876 jetson@192.168.0.104
# Terminal 2:
rerun --serve-web --web-viewer-port 9090 --connect "rerun+http://localhost:9876/proxy"

# Then open in browser: http://localhost:9090

# NOTE: Install rerun via pip (not snap):
pip3 install rerun-sdk




# =============================================================================
# HUGGINGFACE SETUP (ONE-TIME)
# =============================================================================
# Login to HuggingFace (will prompt for token)
huggingface-cli login

# =============================================================================
# RECORDING
# =============================================================================
# VR CONTROLLER CONTROLS:
# Thumbstick UP    → Stop recording
# Thumbstick LEFT  → Re-record current episode
# Thumbstick RIGHT → Save episode & move to next
# Thumbstick DOWN  → Reset robot position

# RECORDING WITH AUTO-PUSH TO HUB (recommended):
lerobot-record \
    --robot.type=xlerobot \
    --teleop.type=xlerobot_vr \
    --dataset.repo_id=Odog16/ob15_test_1 \
    --dataset.single_task="place tools on wooden surface" \
    --dataset.num_episodes=10 \
    --dataset.fps=30 \
    --display_data=true \
    --dataset.push_to_hub=true \
    --resume=true 

# RECORDING LOCAL ONLY (push manually later):
lerobot-record \
    --robot.type=xlerobot \
    --teleop.type=xlerobot_vr \
    --dataset.repo_id=Odog16/ob15_test_1 \
    --dataset.single_task="place clothes in bin" \
    --dataset.num_episodes=10 \
    --dataset.fps=30 \
    --display_data=true

# Manually push to hub after recording:
python -c "from lerobot.datasets.lerobot_dataset import LeRobotDataset; \
    dataset = LeRobotDataset('Odog16/ob15_test_1'); \
    dataset.push_to_hub()"

# Local data location: ~/.cache/huggingface/lerobot/Odog16/ob15_test_1/
# Parquet files: data/chunk-000/episode_*.parquet
# Videos: videos/chunk-000/observation.images.*/episode_*.mp4

# Delete local dataset (if you want to start fresh):
rm -rf ~/.cache/huggingface/lerobot/Odog16/ob15_test_1

# =============================================================================
# PERFORMANCE TIPS
# =============================================================================
# Camera resolution is set to 320x240 for ~30Hz control rate
# To change resolution, edit: src/lerobot/robots/xlerobot/config_xlerobot.py
# - 320x240: ~30 Hz (faster control)
# - 640x480: ~15 Hz (higher quality)
#
# VR CONTROLLER EVENTS (Left Controller):
# - Thumbstick RIGHT: Save episode & move to next
# - Thumbstick LEFT: Re-record current episode
# - Thumbstick UP: Stop recording completely
# - Thumbstick DOWN: Reset robot to zero position

# =============================================================================
# TRAINING POLICY (Run on PC with GPU)
# =============================================================================
lerobot-train \
    --dataset.repo_id=Odog16/ob15_test_1 \
    --policy.type=act \
    --output_dir=outputs/train/act_xlerobot \
    --job_name=act_xlerobot \
    --policy.device=cuda \
    --wandb.enable=true \
    --policy.repo_id=Odog16/xlerobot_policy

# Resume training from checkpoint:
lerobot-train \
    --config_path=outputs/train/act_xlerobot/checkpoints/last/pretrained_model/train_config.json \
    --resume=true

# =============================================================================
# EVALUATE POLICY (Run inference on robot)
# =============================================================================
# Direct evaluation using lerobot-record:
lerobot-record \
    --robot.type=xlerobot \
    --dataset.repo_id=Odog16/eval_xlerobot \
    --dataset.single_task="place clothes in bin" \
    --display_data=false \
    --policy.path=Odog16/xlerobot_policy

# Async inference examples (see ASYNC INFERENCE section below for more details):
python -m lerobot.async_inference.robot_client \
    --server_address=192.168.0.106:8080 \
    --robot.type=xlerobot \
    --task="packing_box" \
    --policy_type=act \
    --pretrained_name_or_path=Odog16/act_200k_ob15_packing_box_policy \
    --policy_device=cuda \
    --actions_per_chunk=120 \
    --chunk_size_threshold=0.5 \
    --aggregate_fn_name="latest_only" \
    --fps=30

python -m lerobot.async_inference.robot_client \
    --server_address=192.168.0.106:8080 \
    --robot.type=xlerobot \
    --task="packing_box" \
    --policy_type=smolvla \
    --pretrained_name_or_path=Odog16/smolvla_ob15_packing_box_policy_2 \
    --policy_device=cuda \
    --actions_per_chunk=80 \
    --chunk_size_threshold=0.3 \
    --aggregate_fn_name="weighted_average" \
    --fps=30




    --robot.port1=/dev/ttyACM1 \
    --robot.port2=/dev/ttyACM2 \
    --robot.port3=/dev/ttyACM0 \
    --robot.cameras="{head: {type: opencv, index_or_path: /dev/video4, width: 640, height: 480, fps: 30, fourcc: MJPG}, left_wrist: {type: opencv, index_or_path: /dev/video2, width: 640, height: 480, fps: 30, fourcc: MJPG}, right_wrist: {type: opencv, index_or_path: /dev/video0, width: 640, height: 480, fps: 30, fourcc: MJPG}}" \



# OPTION 2: Direct evaluation (may hit CUDA OOM on Jetson)
# 
# MODEL SIZE LIMITS FOR JETSON ORIN NANO (8GB):
# - Total system RAM: 8GB (shared with GPU)
# - Available GPU memory: ~4-5GB (after OS overhead)
# - Model size limits:
#   * Small models (<500MB): Should work fine
#   * Medium models (500MB-1GB): May work with optimizations (mixed precision, smaller batch)
#   * Large models (>1GB): Likely to hit OOM (like your 1.2GB SmolVLA model)
# 
# TROUBLESHOOTING CUDA OOM:
# If you get "NvMapMemAllocInternalTagged: error 12" or "CUDACachingAllocator" errors,
# the model (1.2GB) is too large for Jetson GPU memory. Use Option 1 (async) instead.
# 
# For larger Jetson models:
# - Jetson Orin AGX (32GB/64GB): Can handle models up to ~10-20GB
# - Jetson Orin NX (16GB): Can handle models up to ~5-8GB
# 
# DOCKER PERMISSIONS:
# If you get "permission denied" or "unknown server OS" errors, add user to docker group:
#   sudo usermod -aG docker $USER
#   newgrp docker  # or logout/login
# The "unknown server OS" error is often a misleading message when Docker can't connect due to permissions.
# Verify docker access: docker version (should work without sudo after adding to docker group)
docker run --runtime nvidia --env NVIDIA_DRIVER_CAPABILITIES=compute,utility,graphics \
  -it --rm --network host --shm-size=4g \
  --volume /tmp/argus_socket:/tmp/argus_socket \
  --volume /etc/enctune.conf:/etc/enctune.conf \
  --volume /etc/nv_tegra_release:/etc/nv_tegra_release \
  --volume /tmp/nv_jetson_model:/tmp/nv_jetson_model \
  --volume /var/run/dbus:/var/run/dbus \
  --volume /var/run/avahi-daemon/socket:/var/run/avahi-daemon/socket \
  --device /dev/snd -e PULSE_SERVER=unix:/run/user/1000/pulse/native \
  -v /run/user/1000/pulse:/run/user/1000/pulse \
  --device /dev/bus/usb \
  --device /dev/video0 --device /dev/video1 --device /dev/video2 \
  --device /dev/video3 --device /dev/video4 --device /dev/video5 \
  --device /dev/ttyACM0 --device /dev/ttyACM1 --device /dev/ttyACM2 \
  -v /home/jetson/lerobot:/opt/lerobot -w /opt/lerobot \
  dustynv/lerobot:r36.4.0 \
  bash -c "set +H && cd /opt/lerobot && pip install --index-url https://pypi.org/simple --force-reinstall 'numpy<2' && pip install --index-url https://pypi.org/simple 'datasets>=4.0.0,<4.2.0' 'diffusers>=0.27.2,<0.36.0' 'huggingface-hub[hf-transfer,cli]>=0.34.2,<0.36.0' 'accelerate>=1.10.0,<2.0.0' 'setuptools>=71.0.0,<81.0.0' 'cmake>=3.29.0.1,<4.2.0' 'einops>=0.8.0,<0.9.0' 'opencv-python-headless>=4.9.0,<4.13.0' 'av>=15.0.0,<16.0.0' 'jsonlines>=4.0.0,<5.0.0' 'packaging>=24.2,<26.0' 'pynput>=1.7.7,<1.9.0' 'pyserial>=3.5,<4.0' 'wandb>=0.20.0,<0.22.0' 'draccus==0.10.0' 'gymnasium>=1.1.1,<2.0.0' 'rerun-sdk>=0.24.0,<0.27.0' 'deepdiff>=7.0.1,<9.0.0' 'imageio[ffmpeg]>=2.34.0,<3.0.0' 'termcolor>=2.4.0,<4.0.0' 'transformers>=4.53.0,<5.0.0' 'num2words>=0.5.14,<0.6.0' 'safetensors>=0.4.3,<1.0.0' 'feetech-servo-sdk>=1.0.0,<2.0.0' && pip install --index-url https://pypi.org/simple --no-deps -e . && pip install --index-url https://pypi.org/simple --force-reinstall 'numpy<2' && python -c 'import torch; torch.cuda.empty_cache(); assert torch.cuda.is_available(), \"CUDA not available\"; print(f\"CUDA: {torch.cuda.is_available()}, Device: {torch.cuda.get_device_name(0)}, Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")' && python -m lerobot.scripts.lerobot_record --robot.type=xlerobot --dataset.repo_id=Odog16/eval_ob15_packing_box --dataset.single_task=packing_box --dataset.num_episodes=5 --display_data=false --policy.path=Odog16/smolvla_ob15_packing_box_policy_1"




# Split dataset and push to hub
# NOTE: Split names must use underscores, not spaces (Hugging Face repo ID requirement)
# If you get "FileExistsError", delete existing split directories first:
# rm -rf ~/.cache/huggingface/lerobot/Odog16/ob15_packing_box_place_blocks_in_box ~/.cache/huggingface/lerobot/Odog16/ob15_packing_box_pick_box_and_place

lerobot-edit-dataset \
    --repo_id Odog16/ob15_packing_box \
    --operation.type split \
    --operation.splits '{"place_blocks_in_box": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], "pick_box_and_place_blocks_in_box": [75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]}' \
    --push_to_hub true

# This creates two datasets on Hugging Face Hub:
# - Odog16/ob15_packing_box_place_blocks_in_box (75 episodes)
# - Odog16/ob15_packing_box_pick_box_and_place (40 episodes)

# =============================================================================
# DATASET CLEANUP - Delete Unwanted Episodes
# =============================================================================
# Delete specific episodes and keep only the ones you want
# Example: Keep only episodes 740, 1-15 (delete all others)

# First, inspect the dataset to see total episodes:
# python -c "from lerobot.datasets.lerobot_dataset import LeRobotDatasetMetadata; meta = LeRobotDatasetMetadata('Odog16/packing_box'); print(f'Total episodes: {meta.total_episodes}')"

# Then delete unwanted episodes (save to new dataset to preserve original):
# NOTE: You need to specify ALL episodes to DELETE, not the ones to keep
# If you want to keep episodes [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 740],
# you need to delete all other episodes (e.g., if total is 741, delete [0, 16-739])

# Example: Delete episodes 0, 16-739 (keeping 1-15 and 740)
# lerobot-edit-dataset \
#     --repo_id Odog16/packing_box \
#     --new_repo_id Odog16/packing_box_cleaned \
#     --operation.type delete_episodes \
#     --operation.episode_indices "[0, 16, 17, 18, ...]" \
#     --push_to_hub true

# Or delete episodes and overwrite original (WARNING: permanent deletion):
 lerobot-edit-dataset \
     --repo_id Odog16/ob15_packing_box \
     --operation.type delete_episodes \
     --operation.episode_indices "[75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]" \
     --push_to_hub true


# =============================================================================
# GIT WORKFLOW
# =============================================================================
cd /home/jetson/lerobot

# 1. Stage your changes
git add .

# 2. Commit your changes
git commit -m "Your commit message"

# 3. Pull latest changes from remote (merge if needed)
git pull origin main

# 4. Push your changes to remote
# NOTE: First time pushing requires authentication:
#   - Create Personal Access Token: https://github.com/settings/tokens
#   - Select scope: "repo" (full control)
#   - When prompted:
#     * Username: your GitHub username
#     * Password: paste your Personal Access Token (NOT your GitHub password)
#   - Credentials will be saved for future pushes
git push origin main

# If you get authentication errors, ensure remote is HTTPS:
#   git remote set-url origin https://github.com/ImpurestTadpole/lerobot.git
