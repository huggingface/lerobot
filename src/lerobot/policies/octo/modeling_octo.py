#!/usr/bin/env python

# Copyright 2025 HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Octo: An Open-Source Generalist Robot Policy

[Paper](https://arxiv.org/pdf/2405.12213)
[Jax code](https://github.com/octo-models/octo)
[Original Pytorch code](https://github.com/emb-ai/octo-pytorch)
[lilkm Pytorch code](https://github.com/s1lent4gnt/octo-pytorch)

Example of using the octo pretrained model:
```python
policy = OctoPolicy.from_pretrained("lerobot/octo_base")
```

Example of training octo:
```bash
lerobot-train \
--policy.type=octo \
--dataset.repo_id=lilkm/panda_pick_octo_resized \
--batch_size=32 \
--steps=100000
```

"""

from collections import deque
from collections.abc import Sequence

import torch
import torch.nn as nn
from torch import Tensor

from lerobot.constants import ACTION
from lerobot.policies.normalize import Normalize, Unnormalize
from lerobot.policies.octo.configuration_octo import OctoConfig
from lerobot.policies.octo.diffusion import DiffusionActionHead
from lerobot.policies.octo.tokenizers import TextProcessor
from lerobot.policies.octo.transformer import OctoWithoutHead
from lerobot.policies.pretrained import PreTrainedPolicy
from lerobot.policies.utils import log_model_loading_keys, populate_queues

# TODO(lilkm): Be aware of normalization the image tokenizer (normalize_images function)


class OctoPolicy(PreTrainedPolicy):
    """Wrapper class around Octo model to train and run inference within LeRobot."""

    config_class = OctoConfig
    name = "octo"

    def __init__(
        self,
        config: OctoConfig,
        dataset_stats: dict[str, dict[str, Tensor]] | None = None,
    ):
        """
        Args:
            config: Policy configuration class instance or None, in which case the default instantiation of
                    the configuration class is used.
            dataset_stats: Dataset statistics to be used for normalization. If not passed here, it is expected
                    that they will be passed with a call to `load_state_dict` before the policy is used.
        """
        super().__init__(config)
        self.config = config
        self.normalize_inputs = Normalize(config.input_features, config.normalization_mapping, dataset_stats)
        self.normalize_targets = Normalize(
            config.output_features, config.normalization_mapping, dataset_stats
        )
        self.unnormalize_outputs = Unnormalize(
            config.output_features, config.normalization_mapping, dataset_stats
        )

        self.text_processor = TextProcessor(
            tokenizer_name="t5-base",
            tokenizer_kwargs={
                "max_length": 16,
                "padding": "max_length",
                "truncation": True,
                "return_tensors": "pt",
            },
        )

        self.model = OctoDiffusion(self.config)

        # Apply selective freezing based on config
        self._apply_selective_freezing()

        self.reset()

    def reset(self):
        """This should be called whenever the environment is reset."""
        self._queues = {
            ACTION: deque(maxlen=self.config.n_action_steps),
        }

    def _apply_selective_freezing(self):
        """Apply selective freezing based on configuration settings."""
        if hasattr(self.model.octo_transformer, "task_tokenizers"):
            for name, tokenizer in self.model.octo_transformer.task_tokenizers.items():
                if name == "language_instruction":
                    for param in tokenizer.parameters():
                        param.requires_grad = False
                    print("âœ“ T5 language encoder frozen (always frozen during finetuning)")

        # If train_action_head_only is True, freeze everything except the action head
        if self.config.train_action_head_only:
            # Freeze transformer
            for param in self.model.octo_transformer.parameters():
                param.requires_grad = False
            # Keep action head trainable
            for param in self.model.head.parameters():
                param.requires_grad = True
        else:
            # Apply more fine-grained freezing
            if self.config.freeze_transformer:
                for param in self.model.octo_transformer.parameters():
                    param.requires_grad = False

            if self.config.freeze_vision_encoder:
                # Freeze vision encoder components in the transformer
                if hasattr(self.model.octo_transformer, "observation_tokenizers"):
                    for tokenizer in self.model.octo_transformer.observation_tokenizers.values():
                        for param in tokenizer.parameters():
                            param.requires_grad = False

    def get_optim_params(self) -> dict:
        """Return only parameters that require gradients for optimization."""
        return filter(lambda p: p.requires_grad, self.parameters())

    @classmethod
    def _transform_state_dict_keys(cls, state_dict: dict) -> dict:
        """
        Transform state dict keys to match expected model structure.

        This handles the conversion from the new modular octo-pytorch checkpoint format
        to the LeRobot format.
        """
        transformed_dict = {}

        for key, value in state_dict.items():
            # Skip T5 encoder weights - they'll be loaded separately
            if "t5_encoder" in key or "language_tokenizer" in key:
                continue

            # Handle the new modular structure
            new_key = key

            # Add "model." prefix if not present
            if not new_key.startswith("model."):
                new_key = f"model.{new_key}"

            # 1. Replace "action_head." with "head."
            if "action_head." in new_key:
                new_key = new_key.replace("action_head.", "head.")

            # 2. Adjust the transformer nesting to match the LeRobot model.
            # The checkpoint has `transformer.transformer` but LeRobot expects
            # `transformer.transformer.transformer`.
            if "octo_transformer.transformer.transformer." in new_key:
                new_key = new_key.replace(
                    "octo_transformer.transformer.transformer.",
                    "octo_transformer.transformer.transformer.transformer.",
                )

            transformed_dict[new_key] = value

        return transformed_dict

    @classmethod
    def _load_as_safetensor(
        cls, model: "OctoPolicy", model_file: str, map_location: str, strict: bool
    ) -> "OctoPolicy":
        """Override to apply key transformations before loading."""
        from safetensors.torch import load_file

        from lerobot.utils.utils import init_logging

        init_logging()
        # Load the state dict from file safely
        state_dict = load_file(model_file, device=map_location)

        # Apply key transformations
        transformed_state_dict = cls._transform_state_dict_keys(state_dict)

        # Load the transformed state dict
        msg = model.load_state_dict(transformed_state_dict, strict=strict)

        # Log message
        log_model_loading_keys(msg.missing_keys, msg.unexpected_keys)
        return model

    @classmethod
    def from_pretrained(cls, *args, **kwargs):
        """Override the from_pretrained method to display important information."""
        print(
            "ðŸ“¦ Loading Octo pretrained model...\n"
            "   This model was trained on diverse robot manipulation tasks.\n"
            "   Original implementation: https://github.com/octo-models/octo. \n"
            "   lilkm implementation: https://github.com/s1lent4gnt/octo-pytorch"
        )
        return super().from_pretrained(*args, **kwargs)

    def _prepare_batch(
        self, batch: dict[str, Tensor], raw_tasks: Sequence[str] | None = None
    ) -> dict[str, Tensor]:
        """
        Prepare batch for model input.
        Transforms a batch from the LeRobotDataset format to the format expected by the OctoModel.
        """
        # TODO(lilkm): check normalization
        # batch = self.normalize_inputs(batch)
        # Get device from any available tensor in the batch
        device = next(iter(batch.values())).device

        image_primary = batch["observation.images.front"].to(device)
        image_wrist = batch["observation.images.wrist"].to(device)
        proprio = batch["observation.state"].to(device)

        batch_size = image_primary.shape[0]

        if ACTION in batch:
            raw_actions = batch[ACTION].to(device)
        else:
            raw_actions = None

        if raw_tasks is None:
            raw_tasks = [""] * batch_size
        window_size = 1
        action_horizon = self.config.n_action_steps
        action_dim = self.config.action_dim

        image_primary = image_primary.permute(0, 2, 3, 1).unsqueeze(1)
        image_wrist = image_wrist.permute(0, 2, 3, 1).unsqueeze(1)

        proprio = proprio.unsqueeze(1)  # (B, W, D)

        # For window_size=1, timestep will be 0 for all samples
        timestep = torch.zeros((batch_size, window_size), dtype=torch.int32, device=device)

        # Create timestep_pad_mask - all True since we have real data (no padding)
        timestep_pad_mask = torch.ones((batch_size, window_size), dtype=torch.bool, device=device)

        task_completed = torch.zeros(
            (batch_size, window_size, action_horizon), dtype=torch.bool, device=device
        )

        # Create pad_mask_dict for observations
        obs_pad_mask_dict = {
            "image_primary": torch.ones((batch_size, window_size), dtype=torch.bool, device=device),
            "image_wrist": torch.ones((batch_size, window_size), dtype=torch.bool, device=device),
            "proprio": torch.ones((batch_size, window_size), dtype=torch.bool, device=device),
            "timestep": torch.ones((batch_size, window_size), dtype=torch.bool, device=device),
        }

        observations = {
            "image_primary": image_primary,
            "image_wrist": image_wrist,
            "proprio": proprio,
            "timestep": timestep,
            "timestep_pad_mask": timestep_pad_mask,
            "task_completed": task_completed,
            "pad_mask_dict": obs_pad_mask_dict,
        }

        language_instruction = self.text_processor.encode(raw_tasks)
        language_instruction = {k: v.to(device) for k, v in language_instruction.items()}

        tasks = {
            "language_instruction": language_instruction,
            "pad_mask_dict": {
                "language_instruction": torch.ones(batch_size, dtype=torch.bool, device=device)
            },
        }

        # Handle actions only if they're present (during training)
        if raw_actions is not None:
            x_y_z = raw_actions[..., :3]  # x, y, z
            gripper = raw_actions[..., 3:4]  # gripper
            rx_ry_rz = torch.zeros_like(x_y_z, dtype=raw_actions.dtype, device=device)  # rx, ry, rz as zeros
            raw_actions = torch.cat([x_y_z, rx_ry_rz, gripper], dim=-1)  # x, y, z, rx, ry, rz, gripper

            # The dataloader provides a sequence of actions. We select the first `action_horizon`
            # actions to be the target for the diffusion model.
            # raw_actions has shape [batch_size, num_timestamps, action_dim]
            # We need shape [batch_size, window_size, action_horizon, action_dim]

            # Select the first `action_horizon` actions from the sequence.
            actions = raw_actions[:, :action_horizon]

            # Add the window_size dimension.
            actions = actions.unsqueeze(1)

            # Pad if the sequence is shorter than action_horizon.
            if actions.shape[2] < action_horizon:
                padding_shape = (
                    batch_size,
                    window_size,
                    action_horizon - actions.shape[2],
                    action_dim,
                )
                padding = torch.zeros(padding_shape, dtype=actions.dtype, device=actions.device)
                actions = torch.cat([actions, padding], dim=2)

            action_pad_mask = torch.ones_like(actions, dtype=torch.bool, device=device)
            if action_dim >= 7:
                # Mask out rotation dimensions (indices 3, 4, 5)
                action_pad_mask[:, :, :, 3:6] = False
        else:
            # During inference, we don't have actions
            actions = None
            action_pad_mask = None

        return observations, tasks, actions, action_pad_mask, timestep_pad_mask
        # return batch

    def create_tasks(
        self,
        goals: dict[str, torch.Tensor] | None = None,
        texts: Sequence[str] | None = None,
        device: torch.device | None = None,
    ):
        """Creates tasks dict from goals and texts."""
        assert goals is not None or texts is not None
        tasks = {"pad_mask_dict": {}}

        # Determine device
        if device is None:
            if goals is not None:
                device = next(iter(goals.values())).device
            else:
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        if goals is not None:
            tasks.update(goals)
            tasks["pad_mask_dict"].update(
                {k: torch.ones(v.shape[:1], dtype=torch.bool, device=device) for k, v in goals.items()}
            )
        else:
            batch_size = len(texts)
            # Create dummy goals if none are provided
            tasks.update(
                {"image_primary": torch.zeros((batch_size, 256, 256, 3), dtype=torch.uint8, device=device)}
            )
            tasks["pad_mask_dict"].update(
                {
                    k: torch.zeros(batch_size, dtype=torch.bool, device=device)
                    for k in tasks.keys()
                    if k != "pad_mask_dict"
                }
            )

        if texts is not None:
            assert self.text_processor is not None
            encoded = self.text_processor.encode(texts)
            # Move to the correct device
            encoded = {k: v.to(device) for k, v in encoded.items()}
            tasks["language_instruction"] = encoded
            tasks["pad_mask_dict"]["language_instruction"] = torch.ones(
                len(texts), dtype=torch.bool, device=device
            )
        else:
            batch_size = next(iter(goals.values())).shape[0]
            dummy_texts = [""] * batch_size
            encoded = self.text_processor.encode(dummy_texts)
            encoded = {k: v.to(device) for k, v in encoded.items()}
            tasks["language_instruction"] = encoded
            tasks["pad_mask_dict"]["language_instruction"] = torch.zeros(
                batch_size, dtype=torch.bool, device=device
            )

        return tasks

    def _get_action_chunk(self, batch: dict[str, Tensor]) -> Tensor:
        """Get a chunk of actions from the model."""
        # In this method, `batch` is the prepared_batch from `_prepare_batch`
        observations = batch[0]
        tasks = batch[1]
        timestep_pad_mask = batch[4]

        # Get actions from model
        actions = self.model(observations, tasks, timestep_pad_mask)

        # Unnormalize actions
        actions = self.unnormalize_outputs({ACTION: actions})[ACTION]

        return actions

    @torch.no_grad()
    def predict_action_chunk(self, batch: dict[str, Tensor], tasks: Sequence[str] | None = None) -> Tensor:
        """Predict a chunk of actions given environment observations."""
        self.eval()

        # First populate queues with the original batch
        self._queues = populate_queues(self._queues, batch, exclude_keys=[ACTION])
        prepared_batch = self._prepare_batch(batch, raw_tasks=tasks)

        actions = self._get_action_chunk(prepared_batch)
        return actions

    @torch.no_grad()
    def select_action(self, batch: dict[str, Tensor]) -> Tensor:
        """Select a single action given environment observations."""
        self.eval()

        # First, populate queues with the original, simple batch
        self._queues = populate_queues(self._queues, batch, exclude_keys=[ACTION])

        # Then, prepare the complex batch for the model
        prepared_batch = self._prepare_batch(batch)

        # Action queue logic for n_action_steps > 1
        if len(self._queues[ACTION]) == 0:
            # Use the prepared_batch to get actions from the model
            actions = self._get_action_chunk(prepared_batch)

            # actions shape is [batch_size, n_action_steps, action_dim]
            # We need to queue up actions for each sample in the batch
            batch_size = actions.shape[0]

            # For now, just return the first action from the chunk
            # In a real implementation, you'd want to handle the queue per sample
            return actions[:, 0, :]

        return self._queues[ACTION].popleft()

    def forward(self, batch: dict[str, Tensor]) -> dict[str, Tensor]:
        """Do a full training forward pass to compute the loss"""
        # batch = self.normalize_inputs(batch)
        # batch = self.normalize_targets(batch)

        # Prepare batch
        observations, tasks, actions, action_pad_mask, timestep_pad_mask = self._prepare_batch(batch)

        # Get transformer outputs for training
        transformer_outputs = self.model.octo_transformer(observations, tasks, timestep_pad_mask)

        # Compute diffusion loss
        loss, loss_dict = self.model.head.loss(
            transformer_outputs, actions, timestep_pad_mask, action_pad_mask
        )

        return loss, loss_dict


class OctoDiffusion(nn.Module):
    """
    Octo VLA with diffusion action head

    [Paper](https://arxiv.org/pdf/2405.12213)
    """

    def __init__(self, config: OctoConfig):
        super().__init__()
        self.config = config

        self.octo_transformer = OctoWithoutHead(
            model_name=self.config.model_name,
            repeat_task_tokens=self.config.model_name,
            freeze_language_encoder=self.config.freeze_language_encoder,
            token_embedding_size=self.config.token_embedding_size,
            num_layers=self.config.num_layers,
            num_heads=self.config.num_heads,
            mlp_dim=self.config.mlp_dim,
            chunk_size=self.config.chunk_size,
            dropout_rate=self.config.dropout_rate,
            attention_dropout_rate=self.config.attention_dropout_rate,
        )
        self.head = DiffusionActionHead(
            readout_key="readout_action",
            use_map=False,
            input_dim=self.config.token_embedding_size,
            action_dim=self.config.action_dim,
            action_horizon=self.config.n_action_steps,
            diffusion_steps=self.config.diffusion_steps,
            n_diffusion_samples=self.config.n_diffusion_samples,
            max_action=self.config.max_action,
            loss_type=self.config.loss_type,
            time_dim=self.config.time_dim,
            num_blocks=self.config.num_blocks,
            hidden_dim=self.config.hidden_dim,
            use_layer_norm=self.config.use_layer_norm,
            dropout_rate=self.config.dropout_rate,
        )

    def forward(
        self,
        observations: dict[str, torch.Tensor],
        tasks: dict[str, torch.Tensor],
        timestep_pad_mask: torch.Tensor,
        embodiment_action_dim: int | None = None,
    ) -> torch.Tensor:
        transformer_outputs = self.octo_transformer(observations, tasks, timestep_pad_mask)
        actions = self.head.predict_action(
            transformer_outputs=transformer_outputs, embodiment_action_dim=embodiment_action_dim
        )

        return actions
