{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjkBUWm8ZMlc"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bOTfaUaSZKfF"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZC64QGBZ2v9"
      },
      "source": [
        "# Gemini Quickstart: Gemini Robotics-ER 1.5\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/gemini-robotics-er.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81jqmyhKZTZ1"
      },
      "source": [
        "## Gemini Robotics-ER 1.5 Setup\n",
        "\n",
        "This section will need to be run any time you start up Colab. The example sections following this are intended to be able to be run without reliance on any other example section, so you may skip through to the examples that are most relevant/interesting to you at the time (though it is strongly recommended that you read through each of these examples at least once!)\n",
        "\n",
        "To run the following cells, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONn2UcU7akFl"
      },
      "outputs": [],
      "source": [
        "# Install the Google GenAI Python SDK\n",
        "%pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P37Dv6YQaYw9"
      },
      "outputs": [],
      "source": [
        "# @title Declare imports\n",
        "import base64\n",
        "import concurrent.futures\n",
        "import dataclasses\n",
        "from io import BytesIO\n",
        "import json\n",
        "import textwrap\n",
        "import time\n",
        "from typing import Tuple\n",
        "\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "from google.genai import types\n",
        "import IPython\n",
        "from IPython import display\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from PIL import Image, ImageColor, ImageDraw, ImageFont"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZH6qyE1Uacoq"
      },
      "outputs": [],
      "source": [
        "# @title Helper Functions\n",
        "\n",
        "# Json parsing and UI display helpers\n",
        "\n",
        "\n",
        "def parse_json(json_output):\n",
        "  # Parsing out the markdown fencing\n",
        "  lines = json_output.splitlines()\n",
        "  for i, line in enumerate(lines):\n",
        "    if line == \"```json\":\n",
        "      # Remove everything before \"```json\"\n",
        "      json_output = \"\\n\".join(lines[i + 1 :])\n",
        "      # Remove everything after the closing \"```\"\n",
        "      json_output = json_output.split(\"```\")[0]\n",
        "      break  # Exit the loop once \"```json\" is found\n",
        "  return json_output\n",
        "\n",
        "\n",
        "def generate_point_html(pil_image, points_json):\n",
        "  buffered = BytesIO()\n",
        "  pil_image.save(buffered, format=\"PNG\")\n",
        "  img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "  points_json = parse_json(points_json)\n",
        "\n",
        "  return f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Point Visualization</title>\n",
        "    <style>\n",
        "        body {{\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            background: #fff;\n",
        "            color: #000;\n",
        "            font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif;\n",
        "        }}\n",
        "\n",
        "        .point-overlay {{\n",
        "            position: absolute;\n",
        "            top: 0;\n",
        "            left: 0;\n",
        "            width: 100%;\n",
        "            height: 100%;\n",
        "            pointer-events: none;\n",
        "        }}\n",
        "\n",
        "        .point {{\n",
        "            position: absolute;\n",
        "            width: 12px;\n",
        "            height: 12px;\n",
        "            background-color: #2962FF;\n",
        "            border: 2px solid #fff;\n",
        "            border-radius: 50%;\n",
        "            transform: translate(-50%, -50%);\n",
        "            box-shadow: 0 0 40px rgba(41, 98, 255, 0.6);\n",
        "            opacity: 0;\n",
        "            transition: all 0.3s ease-in;\n",
        "            pointer-events: auto;\n",
        "        }}\n",
        "\n",
        "        .point.visible {{\n",
        "            opacity: 1;\n",
        "        }}\n",
        "\n",
        "        .point.fade-out {{\n",
        "            animation: pointFadeOut 0.3s forwards;\n",
        "        }}\n",
        "\n",
        "        .point.highlight {{\n",
        "            transform: translate(-50%, -50%) scale(1.1);\n",
        "            background-color: #FF4081;\n",
        "            box-shadow: 0 0 40px rgba(255, 64, 129, 0.6);\n",
        "            z-index: 100;\n",
        "        }}\n",
        "\n",
        "        @keyframes pointFadeOut {{\n",
        "            from {{\n",
        "                opacity: 1;\n",
        "            }}\n",
        "            to {{\n",
        "                opacity: 0.7;\n",
        "            }}\n",
        "        }}\n",
        "\n",
        "        .point-label {{\n",
        "            position: absolute;\n",
        "            background-color: #2962FF;\n",
        "            color: #fff;\n",
        "            font-size: 14px;\n",
        "            padding: 4px 12px;\n",
        "            border-radius: 4px;\n",
        "            transform: translate(20px, -10px);\n",
        "            white-space: nowrap;\n",
        "            opacity: 0;\n",
        "            transition: all 0.3s ease-in;\n",
        "            box-shadow: 0 0 30px rgba(41, 98, 255, 0.4);\n",
        "            pointer-events: auto;\n",
        "            cursor: pointer;\n",
        "        }}\n",
        "\n",
        "        .point-label.visible {{\n",
        "            opacity: 1;\n",
        "        }}\n",
        "\n",
        "        .point-label.fade-out {{\n",
        "            opacity: 0.45;\n",
        "        }}\n",
        "\n",
        "        .point-label.highlight {{\n",
        "            background-color: #FF4081;\n",
        "            box-shadow: 0 0 30px rgba(255, 64, 129, 0.4);\n",
        "            transform: translate(20px, -10px) scale(1.1);\n",
        "            z-index: 100;\n",
        "        }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"container\" style=\"position: relative;\">\n",
        "        <canvas id=\"canvas\" style=\"background: #000;\"></canvas>\n",
        "        <div id=\"pointOverlay\" class=\"point-overlay\"></div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        function annotatePoints(frame) {{\n",
        "            // Add points with fade effect\n",
        "            const pointsData = {points_json};\n",
        "\n",
        "            const pointOverlay = document.getElementById(\"pointOverlay\");\n",
        "            pointOverlay.innerHTML = \"\";\n",
        "\n",
        "            const points = [];\n",
        "            const labels = [];\n",
        "\n",
        "            pointsData.forEach(pointData => {{\n",
        "                // Skip entries without coodinates.\n",
        "                if (!(pointData.hasOwnProperty(\"point\")))\n",
        "                  return;\n",
        "\n",
        "                const point = document.createElement(\"div\");\n",
        "                point.className = \"point\";\n",
        "                const [y, x] = pointData.point;\n",
        "                point.style.left = `${{x/1000.0 * 100.0}}%`;\n",
        "                point.style.top = `${{y/1000.0 * 100.0}}%`;\n",
        "\n",
        "                const pointLabel = document.createElement(\"div\");\n",
        "                pointLabel.className = \"point-label\";\n",
        "                pointLabel.textContent = pointData.label;\n",
        "                point.appendChild(pointLabel);\n",
        "\n",
        "                pointOverlay.appendChild(point);\n",
        "                points.push(point);\n",
        "                labels.push(pointLabel);\n",
        "\n",
        "                setTimeout(() => {{\n",
        "                    point.classList.add(\"visible\");\n",
        "                    pointLabel.classList.add(\"visible\");\n",
        "                }}, 0);\n",
        "\n",
        "                // Add hover effects\n",
        "                const handleMouseEnter = () => {{\n",
        "                    // Highlight current point and label\n",
        "                    point.classList.add(\"highlight\");\n",
        "                    pointLabel.classList.add(\"highlight\");\n",
        "\n",
        "                    // Fade out other points and labels\n",
        "                    points.forEach((p, idx) => {{\n",
        "                        if (p !== point) {{\n",
        "                            p.classList.add(\"fade-out\");\n",
        "                            labels[idx].classList.add(\"fade-out\");\n",
        "                        }}\n",
        "                    }});\n",
        "                }};\n",
        "\n",
        "                const handleMouseLeave = () => {{\n",
        "                    // Remove highlight from current point and label\n",
        "                    point.classList.remove(\"highlight\");\n",
        "                    pointLabel.classList.remove(\"highlight\");\n",
        "\n",
        "                    // Restore other points and labels\n",
        "                    points.forEach((p, idx) => {{\n",
        "                        p.classList.remove(\"fade-out\");\n",
        "                        labels[idx].classList.remove(\"fade-out\");\n",
        "                    }});\n",
        "                }};\n",
        "\n",
        "                point.addEventListener(\"mouseenter\", handleMouseEnter);\n",
        "                point.addEventListener(\"mouseleave\", handleMouseLeave);\n",
        "                pointLabel.addEventListener(\"mouseenter\", handleMouseEnter);\n",
        "                pointLabel.addEventListener(\"mouseleave\", handleMouseLeave);\n",
        "            }});\n",
        "        }}\n",
        "\n",
        "        // Initialize canvas\n",
        "        const canvas = document.getElementById(\"canvas\");\n",
        "        const ctx = canvas.getContext(\"2d\");\n",
        "        const container = document.getElementById(\"container\");\n",
        "\n",
        "        // Load and draw the image\n",
        "        const img = new Image();\n",
        "        img.onload = () => {{\n",
        "            const aspectRatio = img.height / img.width;\n",
        "            canvas.width = 800;\n",
        "            canvas.height = Math.round(800 * aspectRatio);\n",
        "            container.style.width = canvas.width + \"px\";\n",
        "            container.style.height = canvas.height + \"px\";\n",
        "\n",
        "            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "            frame.width = canvas.width;\n",
        "            frame.height = canvas.height;\n",
        "            annotatePoints(frame);\n",
        "        }};\n",
        "        img.src = \"data:image/png;base64,{img_str}\";\n",
        "\n",
        "        const frame = {{\n",
        "            width: canvas.width,\n",
        "            height: canvas.height\n",
        "        }};\n",
        "\n",
        "        annotatePoints(frame);\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_grasp_html(image, grasp_points, grasp_angles, labels):\n",
        "  buffered = BytesIO()\n",
        "  image.save(buffered, format=\"PNG\")\n",
        "  img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "\n",
        "  grasps = []\n",
        "  for point, angle, label in zip(grasp_points, grasp_angles, labels):\n",
        "    grasp = [\n",
        "        point[0],\n",
        "        point[1],\n",
        "        -angle,\n",
        "    ]\n",
        "    grasps.append({\"point\": grasp, \"label\": label})\n",
        "\n",
        "  return f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Point Visualization</title>\n",
        "    <style>\n",
        "        body {{\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            background: #fff;\n",
        "            color: #000;\n",
        "            font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif;\n",
        "        }}\n",
        "\n",
        "        .point-overlay {{\n",
        "            position: absolute;\n",
        "            top: 0;\n",
        "            left: 0;\n",
        "            width: 100%;\n",
        "            height: 100%;\n",
        "            pointer-events: none;\n",
        "        }}\n",
        "\n",
        "        .point {{\n",
        "            position: absolute;\n",
        "            width: 12px;\n",
        "            height: 12px;\n",
        "            background-color: #2962FF;\n",
        "            border: 2px solid #fff;\n",
        "            border-radius: 50%;\n",
        "            transform: translate(-50%, -50%);\n",
        "            box-shadow: 0 0 40px rgba(41, 98, 255, 0.6);\n",
        "            opacity: 0;\n",
        "            transition: all 0.3s ease-in;\n",
        "            pointer-events: auto;\n",
        "        }}\n",
        "\n",
        "        .point.visible {{\n",
        "            opacity: 1;\n",
        "        }}\n",
        "\n",
        "        .point.fade-out {{\n",
        "            animation: pointFadeOut 0.3s forwards;\n",
        "        }}\n",
        "\n",
        "        .point.highlight {{\n",
        "            transform: translate(-50%, -50%) scale(1.1);\n",
        "            background-color: #FF4081;\n",
        "            box-shadow: 0 0 40px rgba(255, 64, 129, 0.6);\n",
        "            z-index: 100;\n",
        "        }}\n",
        "\n",
        "        @keyframes pointFadeOut {{\n",
        "            from {{\n",
        "                opacity: 1;\n",
        "            }}\n",
        "            to {{\n",
        "                opacity: 0.7;\n",
        "            }}\n",
        "        }}\n",
        "\n",
        "        .point-label {{\n",
        "            position: absolute;\n",
        "            background-color: #2962FF;\n",
        "            color: #fff;\n",
        "            font-size: 14px;\n",
        "            padding: 4px 12px;\n",
        "            border-radius: 4px;\n",
        "            transform: translate(20px, -10px);\n",
        "            white-space: nowrap;\n",
        "            opacity: 0;\n",
        "            transition: all 0.3s ease-in;\n",
        "            box-shadow: 0 0 30px rgba(41, 98, 255, 0.4);\n",
        "            pointer-events: auto;\n",
        "            cursor: pointer;\n",
        "        }}\n",
        "\n",
        "        .point-label.visible {{\n",
        "            opacity: 1;\n",
        "        }}\n",
        "\n",
        "        .point-label.fade-out {{\n",
        "            opacity: 0.45;\n",
        "        }}\n",
        "\n",
        "        .point-label.highlight {{\n",
        "            background-color: #FF4081;\n",
        "            box-shadow: 0 0 30px rgba(255, 64, 129, 0.4);\n",
        "            transform: translate(20px, -10px) scale(1.1);\n",
        "            z-index: 100;\n",
        "        }}\n",
        "\n",
        "        .line {{\n",
        "            position: absolute;\n",
        "            height: 3px;\n",
        "            background-color: #2962FF;\n",
        "            transform-origin: top left;\n",
        "            opacity: 0;\n",
        "            transition: all 0.3s ease-in;\n",
        "            pointer-events: auto;\n",
        "        }}\n",
        "\n",
        "        .line.visible {{\n",
        "            opacity: 1;\n",
        "        }}\n",
        "\n",
        "        .line.fade-out {{\n",
        "            opacity: 0.45;\n",
        "        }}\n",
        "\n",
        "        .line.highlight {{\n",
        "            transform: translate(-50%, -50%) scale(1.1);\n",
        "            background-color: #FF4081;\n",
        "            box-shadow: 0 0 40px rgba(255, 64, 129, 0.6);\n",
        "            z-index: 100;\n",
        "        }}\n",
        "\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"container\" style=\"position: relative;\">\n",
        "        <canvas id=\"canvas\" style=\"background: #000;\"></canvas>\n",
        "        <div id=\"pointOverlay\" class=\"point-overlay\"></div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        function annotatePoints(frame) {{\n",
        "            // Add points with fade effect\n",
        "            const pointsData = {grasps};\n",
        "\n",
        "            const pointOverlay = document.getElementById(\"pointOverlay\");\n",
        "            pointOverlay.innerHTML = \"\";\n",
        "\n",
        "            const points = [];\n",
        "            const labels = [];\n",
        "\n",
        "            pointsData.forEach(pointData => {{\n",
        "                const [y, x, angle] = pointData.point;\n",
        "\n",
        "\n",
        "                const yAbsolute = y / 1000.0 * frame.height;\n",
        "                const xAbsolute = x / 1000.0 * frame.width;\n",
        "                const y0Absolute = yAbsolute - Math.sin(angle / 180 * Math.PI) * 40; // Can change 20 to a higher number for a wider grasp UI\n",
        "                const x0Absolute = xAbsolute - Math.cos(angle / 180 * Math.PI) * 40; // Can change 20 to a higher number for a wider grasp UI\n",
        "                const y1Absolute = yAbsolute + Math.sin(angle / 180 * Math.PI) * 40; // Can change 20 to a higher number for a wider grasp UI\n",
        "                const x1Absolute = xAbsolute + Math.cos(angle / 180 * Math.PI) * 40; // Can change 20 to a higher number for a wider grasp UI\n",
        "\n",
        "                const point1 = document.createElement(\"div\");\n",
        "                point1.className = \"point\";\n",
        "                point1.style.left = `${{x0Absolute}}px`;\n",
        "                point1.style.top = `${{y0Absolute}}px`;\n",
        "\n",
        "                const point2 = document.createElement(\"div\");\n",
        "                point2.className = \"point\";\n",
        "                point2.style.left = `${{x1Absolute}}px`;\n",
        "                point2.style.top = `${{y1Absolute}}px`;\n",
        "\n",
        "                const pointLabel = document.createElement(\"div\");\n",
        "                pointLabel.className = \"point-label\";\n",
        "                pointLabel.textContent = pointData.label;\n",
        "                point2.appendChild(pointLabel);\n",
        "\n",
        "                const deltaX = x1Absolute - x0Absolute;\n",
        "                const deltaY = y1Absolute - y0Absolute;\n",
        "                const length = Math.sqrt(deltaX * deltaX + deltaY * deltaY);\n",
        "\n",
        "                const line = document.createElement(\"div\");\n",
        "                line.className = \"line\";\n",
        "                line.style.width = `${{length}}px`;\n",
        "                line.style.left = `${{x0Absolute}}px`;\n",
        "                line.style.top = `${{y0Absolute}}px`;\n",
        "                line.style.transform = `rotate(${{angle}}deg)`;\n",
        "\n",
        "                pointOverlay.appendChild(point1);\n",
        "                points.push(point1);\n",
        "                pointOverlay.appendChild(point2);\n",
        "                points.push(point2);\n",
        "                pointOverlay.appendChild(line);\n",
        "                points.push(line)\n",
        "                labels.push(pointLabel);\n",
        "\n",
        "                setTimeout(() => {{\n",
        "                    point1.classList.add(\"visible\");\n",
        "                    point2.classList.add(\"visible\");\n",
        "                    line.classList.add(\"visible\");\n",
        "                    pointLabel.classList.add(\"visible\");\n",
        "                }}, 0);\n",
        "\n",
        "                // Add hover effects\n",
        "                const handleMouseEnter = () => {{\n",
        "                    // Highlight current point and label\n",
        "                    point1.classList.add(\"highlight\");\n",
        "                    point2.classList.add(\"highlight\");\n",
        "                    line.classList.add(\"highlight\");\n",
        "                    pointLabel.classList.add(\"highlight\");\n",
        "\n",
        "                    // Fade out other points and labels\n",
        "                    points.forEach((p, idx) => {{\n",
        "                        if (p !== point1 && p !== point2 && p !== line) {{\n",
        "                            p.classList.add(\"fade-out\");\n",
        "                        }}\n",
        "                    }});\n",
        "                    labels.forEach((l, idx) => {{\n",
        "                        if (l != pointLabel) {{\n",
        "                            l.classList.add(\"fade-out\");\n",
        "                        }}\n",
        "                    }});\n",
        "                }};\n",
        "\n",
        "                const handleMouseLeave = () => {{\n",
        "                    // Remove highlight from current point and label\n",
        "                    point1.classList.remove(\"highlight\");\n",
        "                    point2.classList.remove(\"highlight\");\n",
        "                    line.classList.remove(\"highlight\");\n",
        "                    pointLabel.classList.remove(\"highlight\");\n",
        "\n",
        "                    // Restore other points and labels\n",
        "                    points.forEach((p, idx) => {{\n",
        "                        p.classList.remove(\"fade-out\");\n",
        "                    }});\n",
        "                    labels.forEach((l, idx) => {{\n",
        "                        l.classList.remove(\"fade-out\");\n",
        "                    }});\n",
        "                }};\n",
        "\n",
        "                point1.addEventListener(\"mouseenter\", handleMouseEnter);\n",
        "                point1.addEventListener(\"mouseleave\", handleMouseLeave);\n",
        "                point2.addEventListener(\"mouseenter\", handleMouseEnter);\n",
        "                point2.addEventListener(\"mouseleave\", handleMouseLeave);\n",
        "                line.addEventListener(\"mouseenter\", handleMouseEnter);\n",
        "                line.addEventListener(\"mouseleave\", handleMouseLeave);\n",
        "                pointLabel.addEventListener(\"mouseenter\", handleMouseEnter);\n",
        "                pointLabel.addEventListener(\"mouseleave\", handleMouseLeave);\n",
        "            }});\n",
        "        }}\n",
        "\n",
        "        // Initialize canvas\n",
        "        const canvas = document.getElementById(\"canvas\");\n",
        "        const ctx = canvas.getContext(\"2d\");\n",
        "        const container = document.getElementById(\"container\");\n",
        "\n",
        "        // Load and draw the image\n",
        "        const img = new Image();\n",
        "        img.onload = () => {{\n",
        "            const aspectRatio = img.height / img.width;\n",
        "            canvas.width = img.width;\n",
        "            canvas.height = Math.round(img.width * aspectRatio);\n",
        "            container.style.width = canvas.width + \"px\";\n",
        "            container.style.height = canvas.height + \"px\";\n",
        "\n",
        "            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "            frame.width = canvas.width;\n",
        "            frame.height = canvas.height;\n",
        "            annotatePoints(frame);\n",
        "        }};\n",
        "        img.src = \"data:image/png;base64,{img_str}\";\n",
        "\n",
        "        const frame = {{\n",
        "            width: canvas.width,\n",
        "            height: canvas.height\n",
        "        }};\n",
        "\n",
        "        annotatePoints(frame);\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_3d_box_html(image, boxes_json):\n",
        "  buffered = BytesIO()\n",
        "  image.save(buffered, format=\"PNG\")\n",
        "  img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "\n",
        "  return f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>3D Box Visualization</title>\n",
        "    <style>\n",
        "        body {{\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            background: #fff;\n",
        "            color: #000;\n",
        "            font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif;\n",
        "        }}\n",
        "\n",
        "        .view-container {{\n",
        "            display: flex;\n",
        "            gap: 20px;\n",
        "            padding: 20px;\n",
        "            flex-direction: column;\n",
        "            align-items: center;\n",
        "        }}\n",
        "\n",
        "        .canvas-container {{\n",
        "            display: flex;\n",
        "            gap: 20px;\n",
        "        }}\n",
        "\n",
        "        .box-line {{\n",
        "            position: absolute;\n",
        "            background: #2962FF;\n",
        "            transform-origin: 0 0;\n",
        "            opacity: 1;\n",
        "            box-shadow: 0 0 30px rgba(41, 98, 255, 0.4);\n",
        "            transition: all 0.3s ease;\n",
        "            pointer-events: none;\n",
        "        }}\n",
        "\n",
        "        .box-line.highlight {{\n",
        "            background: #FF4081;\n",
        "            box-shadow: 0 0 30px rgba(255, 64, 129, 0.4);\n",
        "            z-index: 100;\n",
        "            border-color: #FF4081 !important;\n",
        "        }}\n",
        "\n",
        "        .box-line.fade {{\n",
        "            opacity: 0.3;\n",
        "        }}\n",
        "\n",
        "        .box-label {{\n",
        "            position: absolute;\n",
        "            color: white;\n",
        "            font-size: 12px;\n",
        "            font-family: Arial;\n",
        "            transform: translate(-50%, -50%);\n",
        "            opacity: 1;\n",
        "            background: #2962FF;\n",
        "            padding: 2px 8px;\n",
        "            border-radius: 4px;\n",
        "            box-shadow: 0 0 30px rgba(41, 98, 255, 0.4);\n",
        "            transition: all 0.3s ease;\n",
        "            cursor: pointer;\n",
        "            z-index: 1000;\n",
        "        }}\n",
        "\n",
        "        .box-label.highlight {{\n",
        "            background: #FF4081;\n",
        "            box-shadow: 0 0 30px rgba(255, 64, 129, 0.4);\n",
        "            transform: translate(-50%, -50%) scale(1.1);\n",
        "            z-index: 1001;\n",
        "        }}\n",
        "\n",
        "        .box-label.fade {{\n",
        "            opacity: 0.3;\n",
        "        }}\n",
        "\n",
        "        .box-overlay {{\n",
        "            position: absolute;\n",
        "            top: 0;\n",
        "            left: 0;\n",
        "            width: 100%;\n",
        "            height: 100%;\n",
        "            pointer-events: none;\n",
        "        }}\n",
        "\n",
        "        .box-overlay .box-label {{\n",
        "            pointer-events: auto;\n",
        "        }}\n",
        "\n",
        "        .controls {{\n",
        "            margin-top: 10px;\n",
        "            background: rgba(0,0,0,0.7);\n",
        "            padding: 10px 20px;\n",
        "            border-radius: 8px;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            gap: 10px;\n",
        "        }}\n",
        "\n",
        "        .slider-label {{\n",
        "            color: white;\n",
        "            font-size: 12px;\n",
        "        }}\n",
        "\n",
        "        input[type=\"range\"] {{\n",
        "            width: 200px;\n",
        "        }}\n",
        "\n",
        "        #topView {{\n",
        "            width: 500px;\n",
        "            height: 500px;\n",
        "            background: #fff;\n",
        "            border: 1px solid #333;\n",
        "            position: relative;\n",
        "            overflow: hidden;\n",
        "        }}\n",
        "\n",
        "        .grid-line {{\n",
        "            position: absolute;\n",
        "            background: #333333;\n",
        "            pointer-events: none;\n",
        "        }}\n",
        "\n",
        "        .grid-label {{\n",
        "            position: absolute;\n",
        "            color: #666666;\n",
        "            font-size: 10px;\n",
        "            pointer-events: none;\n",
        "        }}\n",
        "\n",
        "        .axis-line {{\n",
        "            position: absolute;\n",
        "            background: #666666;\n",
        "            pointer-events: none;\n",
        "        }}\n",
        "\n",
        "        .camera-triangle {{\n",
        "            position: absolute;\n",
        "            width: 0;\n",
        "            height: 0;\n",
        "            border-left: 10px solid transparent;\n",
        "            border-right: 10px solid transparent;\n",
        "            border-bottom: 20px solid #0000ff;\n",
        "            pointer-events: none;\n",
        "        }}\n",
        "\n",
        "        .top-view-container {{\n",
        "            position: relative;\n",
        "        }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"view-container\">\n",
        "        <div class=\"canvas-container\">\n",
        "            <div id=\"container\" style=\"position: relative;\">\n",
        "                <canvas id=\"canvas\" style=\"background: #000;\"></canvas>\n",
        "                <div id=\"boxOverlay\" class=\"box-overlay\"></div>\n",
        "                <div class=\"controls\">\n",
        "                    <span class=\"slider-label\">FOV:</span>\n",
        "                    <input type=\"range\" id=\"fovSlider\" min=\"50\" max=\"120\" value=\"60\" step=\"1\">\n",
        "                    <span id=\"fovValue\">60</span>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"top-view-container\">\n",
        "                <div id=\"topView\">\n",
        "                    <div id=\"topViewOverlay\" class=\"box-overlay\"></div>\n",
        "                </div>\n",
        "                <div class=\"controls\">\n",
        "                    <span class=\"slider-label\">Zoom:</span>\n",
        "                    <input type=\"range\" id=\"zoomSlider\" min=\"0.5\" max=\"3\" value=\"1.5\" step=\"0.1\">\n",
        "                    <span id=\"zoomValue\">1.5x</span>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        let isDragging = {{left: false, right: false}};\n",
        "        let lastX = 0;\n",
        "        let lastY = 0;\n",
        "        let panOffset = {{x: 0, y: 150}};\n",
        "        let boxesData = {boxes_json};\n",
        "\n",
        "        const canvas = document.getElementById(\"canvas\");\n",
        "        const ctx = canvas.getContext(\"2d\");\n",
        "        const container = document.getElementById(\"container\");\n",
        "        const topView = document.getElementById(\"topView\");\n",
        "        const topViewOverlay = document.getElementById(\"topViewOverlay\");\n",
        "\n",
        "        // Load and draw the image\n",
        "        const img = new Image();\n",
        "        img.onload = () => {{\n",
        "            const aspectRatio = img.height / img.width;\n",
        "            canvas.height = 500;\n",
        "            canvas.width = Math.round(500 / aspectRatio);\n",
        "            container.style.width = canvas.width + \"px\";\n",
        "            container.style.height = canvas.height + \"px\";\n",
        "\n",
        "            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "            frame.width = canvas.width;\n",
        "            frame.height = canvas.height;\n",
        "            annotateFrame(frame, parseFloat(fovSlider.value));\n",
        "        }};\n",
        "        img.src = \"data:image/png;base64,{img_str}\";\n",
        "\n",
        "        function highlightBox(label, highlight) {{\n",
        "            const boxOverlay = document.getElementById(\"boxOverlay\");\n",
        "            const topViewOverlay = document.getElementById(\"topViewOverlay\");\n",
        "\n",
        "            [boxOverlay, topViewOverlay].forEach(overlay => {{\n",
        "                const elements = overlay.querySelectorAll(\".box-line, .box-label\");\n",
        "\n",
        "                elements.forEach(element => {{\n",
        "                    if(element.dataset.label === label) {{\n",
        "                        if(highlight) {{\n",
        "                            element.classList.add(\"highlight\");\n",
        "                            element.classList.remove(\"fade\");\n",
        "                        }} else {{\n",
        "                            element.classList.remove(\"highlight\");\n",
        "                            element.classList.remove(\"fade\");\n",
        "                        }}\n",
        "                    }} else {{\n",
        "                        if(highlight) {{\n",
        "                            element.classList.add(\"fade\");\n",
        "                            element.classList.remove(\"highlight\");\n",
        "                        }} else {{\n",
        "                            element.classList.remove(\"fade\");\n",
        "                            element.classList.remove(\"highlight\");\n",
        "                        }}\n",
        "                    }}\n",
        "                }});\n",
        "            }});\n",
        "        }}\n",
        "\n",
        "        function drawTopView() {{\n",
        "            topViewOverlay.innerHTML = \"\";\n",
        "\n",
        "            const zoom = parseFloat(zoomSlider.value);\n",
        "            const viewWidth = 400;\n",
        "            const viewHeight = 400;\n",
        "            const centerX = viewWidth / 2 + panOffset.x;\n",
        "            const centerY = viewHeight / 2 + panOffset.y;\n",
        "\n",
        "            for(let x = -5; x <= 5; x++) {{\n",
        "                const xPixel = centerX + x * (viewWidth/10) * zoom;\n",
        "                const gridLine = document.createElement(\"div\");\n",
        "                gridLine.className = \"grid-line\";\n",
        "                gridLine.style.left = `${{xPixel}}px`;\n",
        "                gridLine.style.top = \"0\";\n",
        "                gridLine.style.width = \"1px\";\n",
        "                gridLine.style.height = \"100%\";\n",
        "                topViewOverlay.appendChild(gridLine);\n",
        "\n",
        "                const label = document.createElement(\"div\");\n",
        "                label.className = \"grid-label\";\n",
        "                label.textContent = x.toString();\n",
        "                label.style.left = `${{xPixel}}px`;\n",
        "                label.style.bottom = \"5px\";\n",
        "                topViewOverlay.appendChild(label);\n",
        "            }}\n",
        "\n",
        "            for(let y = -5; y <= 10; y++) {{\n",
        "                const yPixel = centerY - y * (viewHeight/10) * zoom;\n",
        "                const gridLine = document.createElement(\"div\");\n",
        "                gridLine.className = \"grid-line\";\n",
        "                gridLine.style.left = \"0\";\n",
        "                gridLine.style.top = `${{yPixel}}px`;\n",
        "                gridLine.style.width = \"100%\";\n",
        "                gridLine.style.height = \"1px\";\n",
        "                topViewOverlay.appendChild(gridLine);\n",
        "\n",
        "                const label = document.createElement(\"div\");\n",
        "                label.className = \"grid-label\";\n",
        "                label.textContent = y.toString();\n",
        "                label.style.left = \"5px\";\n",
        "                label.style.top = `${{yPixel}}px`;\n",
        "                topViewOverlay.appendChild(label);\n",
        "            }}\n",
        "\n",
        "            const xAxis = document.createElement(\"div\");\n",
        "            xAxis.className = \"axis-line\";\n",
        "            xAxis.style.left = `${{centerX}}px`;\n",
        "            xAxis.style.top = \"0\";\n",
        "            xAxis.style.width = \"2px\";\n",
        "            xAxis.style.height = \"100%\";\n",
        "            topViewOverlay.appendChild(xAxis);\n",
        "\n",
        "            const yAxis = document.createElement(\"div\");\n",
        "            yAxis.className = \"axis-line\";\n",
        "            yAxis.style.left = \"0\";\n",
        "            yAxis.style.top = `${{centerY}}px`;\n",
        "            yAxis.style.width = \"100%\";\n",
        "            yAxis.style.height = \"2px\";\n",
        "            topViewOverlay.appendChild(yAxis);\n",
        "\n",
        "            const camera = document.createElement(\"div\");\n",
        "            camera.className = \"camera-triangle\";\n",
        "            camera.style.left = `${{centerX - 10}}px`;\n",
        "            camera.style.top = `${{centerY - 20}}px`;\n",
        "            topViewOverlay.appendChild(camera);\n",
        "\n",
        "            boxesData.forEach(boxData => {{\n",
        "                const center = boxData.box_3d.slice(0,3);\n",
        "                const size = boxData.box_3d.slice(3,6);\n",
        "                const rpy = boxData.box_3d.slice(6).map(x => x * Math.PI / 180);\n",
        "\n",
        "                const centerX = viewWidth/2 + center[0] * (viewWidth/10) * zoom + panOffset.x;\n",
        "                const centerY = viewHeight/2 - center[1] * (viewHeight/10) * zoom + panOffset.y;\n",
        "\n",
        "                const box = document.createElement(\"div\");\n",
        "                box.className = \"box-line\";\n",
        "                box.dataset.label = boxData.label;\n",
        "                box.style.width = `${{size[0] * (viewWidth/10) * zoom}}px`;\n",
        "                box.style.height = `${{size[1] * (viewHeight/10) * zoom}}px`;\n",
        "                box.style.left = `${{centerX - (size[0] * (viewWidth/20) * zoom)}}px`;\n",
        "                box.style.top = `${{centerY - (size[1] * (viewHeight/20) * zoom)}}px`;\n",
        "                box.style.transform = `rotate(${{-rpy[2]}}rad)`;\n",
        "                box.style.border = \"2px solid #2962FF\";\n",
        "                box.style.background = \"transparent\";\n",
        "                topViewOverlay.appendChild(box);\n",
        "\n",
        "                const label = document.createElement(\"div\");\n",
        "                label.className = \"box-label\";\n",
        "                label.dataset.label = boxData.label;\n",
        "                label.textContent = boxData.label;\n",
        "                label.style.left = `${{centerX}}px`;\n",
        "                label.style.top = `${{centerY}}px`;\n",
        "\n",
        "                label.addEventListener(\"mouseenter\", () => highlightBox(boxData.label, true));\n",
        "                label.addEventListener(\"mouseleave\", () => highlightBox(boxData.label, false));\n",
        "\n",
        "                topViewOverlay.appendChild(label);\n",
        "            }});\n",
        "        }}\n",
        "\n",
        "        function annotateFrame(frame, fov) {{\n",
        "            const boxOverlay = document.getElementById(\"boxOverlay\");\n",
        "            boxOverlay.innerHTML = \"\";\n",
        "\n",
        "            boxesData.forEach(boxData => {{\n",
        "                const center = boxData.box_3d.slice(0,3);\n",
        "                const size = boxData.box_3d.slice(3,6);\n",
        "                const rpy = boxData.box_3d.slice(6).map(x => x * Math.PI / 180);\n",
        "\n",
        "                const [sr, sp, sy] = rpy.map(x => Math.sin(x/2));\n",
        "                const [cr, cp, cz] = rpy.map(x => Math.cos(x/2));\n",
        "                const quaternion = [\n",
        "                    sr * cp * cz - cr * sp * sy,\n",
        "                    cr * sp * cz + sr * cp * sy,\n",
        "                    cr * cp * sy - sr * sp * cz,\n",
        "                    cr * cp * cz + sr * sp * sy\n",
        "                ];\n",
        "\n",
        "                const height = frame.height;\n",
        "                const width = frame.width;\n",
        "                const f = width / (2 * Math.tan(fov/2 * Math.PI/180));\n",
        "                const cx = width/2;\n",
        "                const cy = height/2;\n",
        "                const intrinsics = [[f, 0, cx], [0, f, cy], [0, 0, 1]];\n",
        "\n",
        "                const halfSize = size.map(s => s/2);\n",
        "                let corners = [];\n",
        "                for(let x of [-halfSize[0], halfSize[0]]) {{\n",
        "                    for(let y of [-halfSize[1], halfSize[1]]) {{\n",
        "                        for(let z of [-halfSize[2], halfSize[2]]) {{\n",
        "                            corners.push([x, y, z]);\n",
        "                        }}\n",
        "                    }}\n",
        "                }}\n",
        "                corners = [\n",
        "                    corners[1], corners[3], corners[7], corners[5],\n",
        "                    corners[0], corners[2], corners[6], corners[4]\n",
        "                ];\n",
        "\n",
        "                const q = quaternion;\n",
        "                const rotationMatrix = [\n",
        "                    [1 - 2*q[1]**2 - 2*q[2]**2, 2*q[0]*q[1] - 2*q[3]*q[2], 2*q[0]*q[2] + 2*q[3]*q[1]],\n",
        "                    [2*q[0]*q[1] + 2*q[3]*q[2], 1 - 2*q[0]**2 - 2*q[2]**2, 2*q[1]*q[2] - 2*q[3]*q[0]],\n",
        "                    [2*q[0]*q[2] - 2*q[3]*q[1], 2*q[1]*q[2] + 2*q[3]*q[0], 1 - 2*q[0]**2 - 2*q[1]**2]\n",
        "                ];\n",
        "\n",
        "                const boxVertices = corners.map(corner => {{\n",
        "                    const rotated = matrixMultiply(rotationMatrix, corner);\n",
        "                    return rotated.map((val, idx) => val + center[idx]);\n",
        "                }});\n",
        "\n",
        "                const tiltAngle = 90.0;\n",
        "                const viewRotationMatrix = [\n",
        "                    [1, 0, 0],\n",
        "                    [0, Math.cos(tiltAngle * Math.PI/180), -Math.sin(tiltAngle * Math.PI/180)],\n",
        "                    [0, Math.sin(tiltAngle * Math.PI/180), Math.cos(tiltAngle * Math.PI/180)]\n",
        "                ];\n",
        "\n",
        "                const points = boxVertices;\n",
        "                const rotatedPoints = points.map(p => matrixMultiply(viewRotationMatrix, p));\n",
        "                const translatedPoints = rotatedPoints.map(p => p.map(v => v + 0));\n",
        "\n",
        "                const vertexDistances = translatedPoints.map(p =>\n",
        "                    Math.sqrt(p[0]*p[0] + p[1]*p[1] + p[2]*p[2])\n",
        "                );\n",
        "\n",
        "                const minDist = Math.min(...vertexDistances);\n",
        "                const maxDist = Math.max(...vertexDistances);\n",
        "                const distRange = maxDist - minDist;\n",
        "\n",
        "                const projectedPoints = translatedPoints.map(p => matrixMultiply(intrinsics, p));\n",
        "                const vertices = projectedPoints.map(p => [p[0]/p[2], p[1]/p[2]]);\n",
        "\n",
        "                const topVertices = vertices.slice(0,4);\n",
        "                const bottomVertices = vertices.slice(4,8);\n",
        "                const topDistances = vertexDistances.slice(0,4);\n",
        "                const bottomDistances = vertexDistances.slice(4,8);\n",
        "\n",
        "                for(let i = 0; i < 4; i++) {{\n",
        "                    const lines = [\n",
        "                        {{start: topVertices[i], end: topVertices[(i + 1) % 4],\n",
        "                         dist: (topDistances[i] + topDistances[(i + 1) % 4]) / 2}},\n",
        "                        {{start: bottomVertices[i], end: bottomVertices[(i + 1) % 4],\n",
        "                         dist: (bottomDistances[i] + bottomDistances[(i + 1) % 4]) / 2}},\n",
        "                        {{start: topVertices[i], end: bottomVertices[i],\n",
        "                         dist: (topDistances[i] + bottomDistances[i]) / 2}}\n",
        "                    ];\n",
        "\n",
        "                    for(let {{start, end, dist}} of lines) {{\n",
        "                        const line = document.createElement(\"div\");\n",
        "                        line.className = \"box-line\";\n",
        "                        line.dataset.label = boxData.label;\n",
        "\n",
        "                        const dx = end[0] - start[0];\n",
        "                        const dy = end[1] - start[1];\n",
        "                        const length = Math.sqrt(dx*dx + dy*dy);\n",
        "                        const angle = Math.atan2(dy, dx);\n",
        "\n",
        "                        const normalizedDist = (dist - minDist) / distRange;\n",
        "\n",
        "                        const maxWidth = 4;\n",
        "                        const minWidth = 1;\n",
        "                        const width = maxWidth - normalizedDist * (maxWidth - minWidth);\n",
        "\n",
        "                        line.style.width = `${{length}}px`;\n",
        "                        line.style.height = `${{width}}px`;\n",
        "                        line.style.transform = `translate(${{start[0]}}px, ${{start[1]}}px) rotate(${{angle}}rad)`;\n",
        "\n",
        "                        boxOverlay.appendChild(line);\n",
        "                    }}\n",
        "                }}\n",
        "\n",
        "                const textPosition3d = points[0].map((val, idx) =>\n",
        "                    points.reduce((sum, p) => sum + p[idx], 0) / points.length\n",
        "                );\n",
        "                textPosition3d[2] += 0.1;\n",
        "\n",
        "                const textPoint = matrixMultiply(intrinsics,\n",
        "                    matrixMultiply(viewRotationMatrix, textPosition3d.map(v => v + 0))\n",
        "                );\n",
        "                const textPos = [textPoint[0]/textPoint[2], textPoint[1]/textPoint[2]];\n",
        "\n",
        "                const label = document.createElement(\"div\");\n",
        "                label.className = \"box-label\";\n",
        "                label.dataset.label = boxData.label;\n",
        "                label.textContent = boxData.label;\n",
        "                label.style.left = `${{textPos[0]}}px`;\n",
        "                label.style.top = `${{textPos[1]}}px`;\n",
        "\n",
        "                label.addEventListener(\"mouseenter\", () => highlightBox(boxData.label, true));\n",
        "                label.addEventListener(\"mouseleave\", () => highlightBox(boxData.label, false));\n",
        "\n",
        "                boxOverlay.appendChild(label);\n",
        "            }});\n",
        "        }}\n",
        "\n",
        "        function matrixMultiply(m, v) {{\n",
        "            return m.map(row =>\n",
        "                row.reduce((sum, val, i) => sum + val * v[i], 0)\n",
        "            );\n",
        "        }}\n",
        "\n",
        "        const frame = {{\n",
        "            width: canvas.width,\n",
        "            height: canvas.height\n",
        "        }};\n",
        "\n",
        "        const fovSlider = document.getElementById(\"fovSlider\");\n",
        "        const fovValue = document.getElementById(\"fovValue\");\n",
        "        const zoomSlider = document.getElementById(\"zoomSlider\");\n",
        "        const zoomValue = document.getElementById(\"zoomValue\");\n",
        "\n",
        "        fovSlider.addEventListener(\"input\", (e) => {{\n",
        "            const fov = parseFloat(e.target.value);\n",
        "            fovValue.textContent = `${{fov}}`;\n",
        "            annotateFrame(frame, fov);\n",
        "            drawTopView();\n",
        "        }});\n",
        "\n",
        "        zoomSlider.addEventListener(\"input\", (e) => {{\n",
        "            const zoom = parseFloat(e.target.value);\n",
        "            zoomValue.textContent = `${{zoom}}x`;\n",
        "            drawTopView();\n",
        "        }});\n",
        "\n",
        "        function handleMouseDown(e, view) {{\n",
        "            isDragging[view] = true;\n",
        "            lastX = e.clientX;\n",
        "            lastY = e.clientY;\n",
        "        }}\n",
        "\n",
        "        function handleMouseMove(e, view) {{\n",
        "            if (isDragging[view]) {{\n",
        "                const deltaX = e.clientX - lastX;\n",
        "                const deltaY = e.clientY - lastY;\n",
        "\n",
        "                if (view === \"left\") {{\n",
        "                    boxesData = boxesData.map(boxData => {{\n",
        "                        const newBox3d = [...boxData.box_3d];\n",
        "                        newBox3d[0] += deltaX * 0.001;\n",
        "                        newBox3d[2] -= deltaY * 0.001;\n",
        "                        return {{...boxData, box_3d: newBox3d}};\n",
        "                    }});\n",
        "                }} else {{\n",
        "                    panOffset.x += deltaX;\n",
        "                    panOffset.y += deltaY;\n",
        "                }}\n",
        "\n",
        "                lastX = e.clientX;\n",
        "                lastY = e.clientY;\n",
        "\n",
        "                annotateFrame(frame, parseFloat(fovSlider.value));\n",
        "                drawTopView();\n",
        "            }}\n",
        "        }}\n",
        "\n",
        "        function handleMouseUp(view) {{\n",
        "            isDragging[view] = false;\n",
        "        }}\n",
        "\n",
        "        canvas.addEventListener(\"mousedown\", (e) => handleMouseDown(e, \"left\"));\n",
        "        canvas.addEventListener(\"mousemove\", (e) => handleMouseMove(e, \"left\"));\n",
        "        canvas.addEventListener(\"mouseup\", () => handleMouseUp(\"left\"));\n",
        "        canvas.addEventListener(\"mouseleave\", () => handleMouseUp(\"left\"));\n",
        "\n",
        "        topView.addEventListener(\"mousedown\", (e) => handleMouseDown(e, \"right\"));\n",
        "        topView.addEventListener(\"mousemove\", (e) => handleMouseMove(e, \"right\"));\n",
        "        topView.addEventListener(\"mouseup\", () => handleMouseUp(\"right\"));\n",
        "        topView.addEventListener(\"mouseleave\", () => handleMouseUp(\"right\"));\n",
        "\n",
        "        annotateFrame(frame, 60);\n",
        "        drawTopView();\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# @title Plotting Util\n",
        "\n",
        "additional_colors = [\n",
        "    colorname for (colorname, colorcode) in ImageColor.colormap.items()\n",
        "]\n",
        "\n",
        "\n",
        "def plot_bounding_boxes(img, bounding_boxes):\n",
        "  \"\"\"Plots bounding boxes on an image.\n",
        "\n",
        "  Plots bounding boxes on an image with markers for each a name, using PIL,\n",
        "  normalized coordinates, and different colors.\n",
        "\n",
        "  Args:\n",
        "      img_path: The path to the image file.\n",
        "      bounding_boxes: A list of bounding boxes containing the name of the object\n",
        "        and their positions in normalized [y1 x1 y2 x2] format.\n",
        "  \"\"\"\n",
        "\n",
        "  # Load the image\n",
        "  width, height = img.size\n",
        "  print(img.size)\n",
        "  # Create a drawing object\n",
        "  draw = ImageDraw.Draw(img)\n",
        "\n",
        "  # Define a list of colors\n",
        "  colors = [\n",
        "      \"red\",\n",
        "      \"green\",\n",
        "      \"blue\",\n",
        "      \"yellow\",\n",
        "      \"orange\",\n",
        "      \"pink\",\n",
        "      \"purple\",\n",
        "      \"brown\",\n",
        "      \"gray\",\n",
        "      \"beige\",\n",
        "      \"turquoise\",\n",
        "      \"cyan\",\n",
        "      \"magenta\",\n",
        "      \"lime\",\n",
        "      \"navy\",\n",
        "      \"maroon\",\n",
        "      \"teal\",\n",
        "      \"olive\",\n",
        "      \"coral\",\n",
        "      \"lavender\",\n",
        "      \"violet\",\n",
        "      \"gold\",\n",
        "      \"silver\",\n",
        "  ] + additional_colors\n",
        "\n",
        "  # Parsing out the markdown fencing\n",
        "  bounding_boxes = parse_json(bounding_boxes)\n",
        "\n",
        "  font = ImageFont.truetype(\"LiberationSans-Regular.ttf\", size=14)\n",
        "\n",
        "  # Iterate over the bounding boxes\n",
        "  for i, bounding_box in enumerate(json.loads(bounding_boxes)):\n",
        "    # Select a color from the list\n",
        "    color = colors[i % len(colors)]\n",
        "\n",
        "    # Convert normalized coordinates to absolute coordinates\n",
        "    abs_y1 = int(bounding_box[\"box_2d\"][0] / 1000 * height)\n",
        "    abs_x1 = int(bounding_box[\"box_2d\"][1] / 1000 * width)\n",
        "    abs_y2 = int(bounding_box[\"box_2d\"][2] / 1000 * height)\n",
        "    abs_x2 = int(bounding_box[\"box_2d\"][3] / 1000 * width)\n",
        "\n",
        "    if abs_x1 > abs_x2:\n",
        "      abs_x1, abs_x2 = abs_x2, abs_x1\n",
        "\n",
        "    if abs_y1 > abs_y2:\n",
        "      abs_y1, abs_y2 = abs_y2, abs_y1\n",
        "\n",
        "    # Draw the bounding box\n",
        "    draw.rectangle(((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4)\n",
        "\n",
        "    # Draw the text\n",
        "    if \"label\" in bounding_box:\n",
        "      draw.text(\n",
        "          (abs_x1 + 8, abs_y1 + 6), bounding_box[\"label\"], fill=color, font=font\n",
        "      )\n",
        "\n",
        "  # Display the image\n",
        "  img.show()\n",
        "\n",
        "\n",
        "@dataclasses.dataclass(frozen=True)\n",
        "class SegmentationMask:\n",
        "  # bounding box pixel coordinates (not normalized)\n",
        "  y0: int  # in [0..height - 1]\n",
        "  x0: int  # in [0..width - 1]\n",
        "  y1: int  # in [0..height - 1]\n",
        "  x1: int  # in [0..width - 1]\n",
        "  mask: np.array  # [img_height, img_width] with values 0..255\n",
        "  label: str\n",
        "\n",
        "\n",
        "def parse_segmentation_masks(\n",
        "    predicted_str: str, *, img_height: int, img_width: int\n",
        ") -> list[SegmentationMask]:\n",
        "  items = json.loads(parse_json(predicted_str))\n",
        "  masks = []\n",
        "  for item in items:\n",
        "    raw_box = item[\"box_2d\"]\n",
        "    abs_y0 = int(item[\"box_2d\"][0] / 1000 * img_height)\n",
        "    abs_x0 = int(item[\"box_2d\"][1] / 1000 * img_width)\n",
        "    abs_y1 = int(item[\"box_2d\"][2] / 1000 * img_height)\n",
        "    abs_x1 = int(item[\"box_2d\"][3] / 1000 * img_width)\n",
        "    if abs_y0 >= abs_y1 or abs_x0 >= abs_x1:\n",
        "      print(\"Invalid bounding box\", item[\"box_2d\"])\n",
        "      continue\n",
        "    label = item[\"label\"]\n",
        "    png_str = item[\"mask\"]\n",
        "    if not png_str.startswith(\"data:image/png;base64,\"):\n",
        "      print(\"Invalid mask\")\n",
        "      continue\n",
        "    png_str = png_str.removeprefix(\"data:image/png;base64,\")\n",
        "    png_str = base64.b64decode(png_str)\n",
        "    mask = Image.open(BytesIO(png_str))\n",
        "    bbox_height = abs_y1 - abs_y0\n",
        "    bbox_width = abs_x1 - abs_x0\n",
        "    if bbox_height < 1 or bbox_width < 1:\n",
        "      print(\"Invalid bounding box\")\n",
        "      continue\n",
        "    mask = mask.resize(\n",
        "        (bbox_width, bbox_height), resample=Image.Resampling.BILINEAR\n",
        "    )\n",
        "    np_mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
        "    np_mask[abs_y0:abs_y1, abs_x0:abs_x1] = mask\n",
        "    masks.append(\n",
        "        SegmentationMask(abs_y0, abs_x0, abs_y1, abs_x1, np_mask, label)\n",
        "    )\n",
        "  return masks\n",
        "\n",
        "\n",
        "def overlay_mask_on_img(\n",
        "    img: Image, mask: np.ndarray, color: str, alpha: float = 0.7\n",
        ") -> Image.Image:\n",
        "  \"\"\"Overlays a single mask onto a PIL Image using a named color.\n",
        "\n",
        "  The mask image defines the area to be colored. Non-zero pixels in the\n",
        "  mask image are considered part of the area to overlay.\n",
        "\n",
        "  Args:\n",
        "      img: The base PIL Image object.\n",
        "      mask: A PIL Image object representing the mask. Should have the same\n",
        "        height and width as the img. Modes '1' (binary) or 'L' (grayscale) are\n",
        "        typical, where non-zero pixels indicate the masked area.\n",
        "      color: A standard color name string (e.g., 'red', 'blue', 'yellow').\n",
        "      alpha: The alpha transparency level for the overlay (0.0 fully\n",
        "        transparent, 1.0 fully opaque). Default is 0.7 (70%).\n",
        "\n",
        "  Returns:\n",
        "      A new PIL Image object (in RGBA mode) with the mask overlaid.\n",
        "\n",
        "  Raises:\n",
        "      ValueError: If color name is invalid, mask dimensions mismatch img\n",
        "                  dimensions, or alpha is outside the 0.0-1.0 range.\n",
        "  \"\"\"\n",
        "  if not (0.0 <= alpha <= 1.0):\n",
        "    raise ValueError(\"Alpha must be between 0.0 and 1.0\")\n",
        "\n",
        "  # Convert the color name string to an RGB tuple\n",
        "  try:\n",
        "    color_rgb: Tuple[int, int, int] = ImageColor.getrgb(color)\n",
        "  except ValueError as e:\n",
        "    # Re-raise with a more informative message if color name is invalid\n",
        "    raise ValueError(\n",
        "        f\"Invalid color name '{color}'. Supported names are typically HTML/CSS \"\n",
        "        f\"color names. Error: {e}\"\n",
        "    )\n",
        "\n",
        "  # Prepare the base image for alpha compositing\n",
        "  img_rgba = img.convert(\"RGBA\")\n",
        "  width, height = img_rgba.size\n",
        "\n",
        "  # Create the colored overlay layer\n",
        "  # Calculate the RGBA tuple for the overlay color\n",
        "  alpha_int = int(alpha * 255)\n",
        "  overlay_color_rgba = color_rgb + (alpha_int,)\n",
        "\n",
        "  # Create an RGBA layer (all zeros = transparent black)\n",
        "  colored_mask_layer_np = np.zeros((height, width, 4), dtype=np.uint8)\n",
        "\n",
        "  # Mask has values between 0 and 255, threshold at 127 to get binary mask.\n",
        "  mask_np_logical = mask > 127\n",
        "\n",
        "  # Apply the overlay color RGBA tuple where the mask is True\n",
        "  colored_mask_layer_np[mask_np_logical] = overlay_color_rgba\n",
        "\n",
        "  # Convert the NumPy layer back to a PIL Image\n",
        "  colored_mask_layer_pil = Image.fromarray(colored_mask_layer_np, \"RGBA\")\n",
        "\n",
        "  # Composite the colored mask layer onto the base image\n",
        "  result_img = Image.alpha_composite(img_rgba, colored_mask_layer_pil)\n",
        "\n",
        "  return result_img\n",
        "\n",
        "\n",
        "def plot_segmentation_masks(\n",
        "    img: Image, segmentation_masks: list[SegmentationMask]\n",
        "):\n",
        "  \"\"\"Plots bounding boxes on an image.\n",
        "\n",
        "  Plots bounding boxes on an image with markers for each a name, using PIL,\n",
        "  normalized coordinates, and different colors.\n",
        "\n",
        "  Args:\n",
        "      img: The PIL.Image.\n",
        "      segmentation_masks: A string encoding as JSON a list of segmentation masks\n",
        "        containing the name of the object, their positions in normalized [y1 x1\n",
        "        y2 x2] format, and the png encoded segmentation mask.\n",
        "  \"\"\"\n",
        "  # Define a list of colors\n",
        "  colors = [\n",
        "      \"red\",\n",
        "      \"green\",\n",
        "      \"blue\",\n",
        "      \"yellow\",\n",
        "      \"orange\",\n",
        "      \"pink\",\n",
        "      \"purple\",\n",
        "      \"brown\",\n",
        "      \"gray\",\n",
        "      \"beige\",\n",
        "      \"turquoise\",\n",
        "      \"cyan\",\n",
        "      \"magenta\",\n",
        "      \"lime\",\n",
        "      \"navy\",\n",
        "      \"maroon\",\n",
        "      \"teal\",\n",
        "      \"olive\",\n",
        "      \"coral\",\n",
        "      \"lavender\",\n",
        "      \"violet\",\n",
        "      \"gold\",\n",
        "      \"silver\",\n",
        "  ] + additional_colors\n",
        "\n",
        "  font = ImageFont.load_default()\n",
        "\n",
        "  # Do this in 3 passes to make sure the boxes and text are always visible.\n",
        "\n",
        "  # Overlay the mask\n",
        "  for i, mask in enumerate(segmentation_masks):\n",
        "    color = colors[i % len(colors)]\n",
        "    img = overlay_mask_on_img(img, mask.mask, color)\n",
        "\n",
        "  # Create a drawing object\n",
        "  draw = ImageDraw.Draw(img)\n",
        "\n",
        "  # Draw the bounding boxes\n",
        "  for i, mask in enumerate(segmentation_masks):\n",
        "    color = colors[i % len(colors)]\n",
        "    draw.rectangle(\n",
        "        ((mask.x0, mask.y0), (mask.x1, mask.y1)), outline=color, width=4\n",
        "    )\n",
        "\n",
        "  # Draw the text labels\n",
        "  for i, mask in enumerate(segmentation_masks):\n",
        "    color = colors[i % len(colors)]\n",
        "    if mask.label != \"\":\n",
        "      draw.text((mask.x0 + 8, mask.y0 - 20), mask.label, fill=color, font=font)\n",
        "  return img\n",
        "\n",
        "\n",
        "def overlay_points_on_frames(original_frames, points_data_per_frame):\n",
        "  \"\"\"Overlays points on original frames and returns the modified frames.\"\"\"\n",
        "  modified_frames = []\n",
        "\n",
        "  # Define colors for drawing points (using a consistent color per label for clarity)\n",
        "  label_colors = {}\n",
        "  current_color_index = 0\n",
        "  available_colors = [\n",
        "      \"red\",\n",
        "      \"green\",\n",
        "      \"blue\",\n",
        "      \"yellow\",\n",
        "      \"orange\",\n",
        "      \"pink\",\n",
        "      \"purple\",\n",
        "      \"brown\",\n",
        "      \"gray\",\n",
        "      \"beige\",\n",
        "      \"turquoise\",\n",
        "      \"cyan\",\n",
        "      \"magenta\",\n",
        "      \"lime\",\n",
        "      \"navy\",\n",
        "      \"maroon\",\n",
        "      \"teal\",\n",
        "      \"olive\",\n",
        "      \"coral\",\n",
        "      \"lavender\",\n",
        "      \"violet\",\n",
        "      \"gold\",\n",
        "      \"silver\",\n",
        "  ]\n",
        "\n",
        "  font = ImageFont.load_default()\n",
        "\n",
        "  # Check if the number of original frames matches the number of processed data entries\n",
        "  if len(original_frames) != len(points_data_per_frame):\n",
        "    print(\n",
        "        f\"Error: Number of original frames ({len(original_frames)}) does not \"\n",
        "        \"match the number of processed point data entries\"\n",
        "        f\" ({len(points_data_per_frame)}). Cannot overlay points accurately.\"\n",
        "    )\n",
        "    return original_frames  # Return original frames if data doesn't match\n",
        "  else:\n",
        "    # Iterate through the frames and draw points\n",
        "    for i, frame_pil in enumerate(original_frames):\n",
        "      # Ensure frame is in RGB mode for drawing\n",
        "      img = frame_pil.convert(\"RGB\")\n",
        "      draw = ImageDraw.Draw(img)\n",
        "      width, height = img.size\n",
        "\n",
        "      frame_points = points_data_per_frame[i]\n",
        "\n",
        "      # Draw points on the frame\n",
        "      for point_info in frame_points:\n",
        "        if \"point\" in point_info and \"label\" in point_info:\n",
        "          y_norm, x_norm = point_info[\"point\"]\n",
        "          label = point_info[\"label\"]\n",
        "\n",
        "          # Get color for the label\n",
        "          if label not in label_colors:\n",
        "            label_colors[label] = available_colors[\n",
        "                current_color_index % len(available_colors)\n",
        "            ]\n",
        "            current_color_index += 1\n",
        "          color = label_colors[label]\n",
        "\n",
        "          # Convert normalized coordinates to absolute pixel coordinates\n",
        "          abs_x = int(x_norm / 1000.0 * width)\n",
        "          abs_y = int(y_norm / 1000.0 * height)\n",
        "\n",
        "          # Draw a circle at the point\n",
        "          point_radius = 5\n",
        "          draw.ellipse(\n",
        "              (\n",
        "                  abs_x - point_radius,\n",
        "                  abs_y - point_radius,\n",
        "                  abs_x + point_radius,\n",
        "                  abs_y + point_radius,\n",
        "              ),\n",
        "              fill=color,\n",
        "              outline=color,\n",
        "          )\n",
        "\n",
        "          # Draw the label\n",
        "          # Adjust label position to avoid going out of bounds\n",
        "          label_pos_x = abs_x + point_radius + 2\n",
        "          label_pos_y = (\n",
        "              abs_y - point_radius - 10\n",
        "              if abs_y - point_radius - 10 > 0\n",
        "              else abs_y + point_radius + 2\n",
        "          )\n",
        "          draw.text((label_pos_x, label_pos_y), label, fill=color, font=font)\n",
        "\n",
        "      # Append the modified PIL Image\n",
        "      modified_frames.append(img)\n",
        "\n",
        "    print(f\"Processed and drew points on {len(modified_frames)} frames.\")\n",
        "    return modified_frames\n",
        "\n",
        "\n",
        "def display_gif(frames_to_display):\n",
        "  \"\"\"Saves and displays a list of PIL Images as a GIF.\"\"\"\n",
        "  if frames_to_display:\n",
        "    try:\n",
        "      # Save the modified frames as a new GIF\n",
        "      output_gif_path = \"/tmp/annotated_aloha_pen.gif\"\n",
        "      # Duration per frame in milliseconds (adjust as needed, 40ms is 25fps)\n",
        "      duration_ms = 40\n",
        "      # Ensure all frames are in RGB mode before saving as GIF\n",
        "      rgb_frames = [frame.convert(\"RGB\") for frame in frames_to_display]\n",
        "      if rgb_frames:\n",
        "        rgb_frames[0].save(\n",
        "            output_gif_path,\n",
        "            save_all=True,\n",
        "            append_images=rgb_frames[1:],\n",
        "            duration=duration_ms,\n",
        "            loop=0,\n",
        "        )\n",
        "\n",
        "        # Display the GIF in Colab\n",
        "        display.display(display.Image(output_gif_path))\n",
        "        print(f\"Displayed annotated GIF: {output_gif_path}\")\n",
        "      else:\n",
        "        print(\"No frames to create GIF.\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error creating or displaying annotated GIF: {e}\")\n",
        "  else:\n",
        "    print(\"No frames to display.\")\n",
        "\n",
        "\n",
        "def extract_frames(gif):\n",
        "  \"\"\"Extracts frames from a GIF and returns a list of PIL Image objects.\"\"\"\n",
        "  frames = []\n",
        "  try:\n",
        "    while True:\n",
        "      # Convert each frame to RGB to ensure compatibility with drawing\n",
        "      frame = gif.convert(\"RGB\")\n",
        "      frames.append(frame)\n",
        "      gif.seek(gif.tell() + 1)  # Move to the next frame\n",
        "  except EOFError:\n",
        "    pass  # End of sequence\n",
        "\n",
        "  print(f\"Extracted {len(frames)} frames from the GIF.\")\n",
        "\n",
        "  return frames\n",
        "\n",
        "\n",
        "def populate_points_for_all_frames(total_frames, step, analyzed_data):\n",
        "  \"\"\"Populates point data for all frames based on analyzed frames.\"\"\"\n",
        "  points_data_all_frames = []\n",
        "  analyzed_data_index = 0\n",
        "  for i in range(total_frames):\n",
        "    if i % step == 0 and analyzed_data_index < len(analyzed_data):\n",
        "      points_data_all_frames.append(analyzed_data[analyzed_data_index])\n",
        "      analyzed_data_index += 1\n",
        "    else:\n",
        "      # For frames that were not analyzed, use the data from the last analyzed\n",
        "      # frame or append an empty list if no frame has been analyzed yet\n",
        "      if analyzed_data_index > 0:\n",
        "        points_data_all_frames.append(analyzed_data[analyzed_data_index - 1])\n",
        "      else:\n",
        "        # Should not happen if frames list is not empty\n",
        "        points_data_all_frames.append([])\n",
        "  return points_data_all_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2epDtCqJagUj"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Templates for Common Actions\n",
        "\n",
        "GRASP_PROMPT_TEMPLATE = textwrap.dedent(\"\"\"\\\n",
        "    Determine the bounding box of the $object and point to the $part of the\n",
        "    $object. Then, find the angle (between -90 and 90 degrees) that would be a\n",
        "    suitable grasp angle at this point. Return the answer in the format:\n",
        "\n",
        "    ```json\n",
        "    [\n",
        "      {\"box_2d\": [], \"label\": \"$object\"},\n",
        "      {\"point\": [], \"label\": \"$part\"},\n",
        "      {\"angle\": int, \"label\": \"$part\"}\n",
        "    ]\n",
        "    ```\"\"\")\n",
        "\n",
        "POINT_ALL_PROMPT_TEMPLATE = textwrap.dedent(\"\"\"\\\n",
        "    Point to all $object in the image. Return the answer as a JSON list of\n",
        "    dictionaries with keys 'point' and 'label'.\"\"\")\n",
        "\n",
        "POINT_PROMPT_TEMPLATE = textwrap.dedent(\"\"\"\\\n",
        "    Point to the $part of the $object in the image. Return the answer as a\n",
        "    JSON list of a dictionary with keys 'point' and 'label'. Only return one\n",
        "    point for this request.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L0iD346and2"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ezNXUK8arKa"
      },
      "outputs": [],
      "source": [
        "# Initialize the GenAI client with the Gemini Robotics ER model, then test that\n",
        "# it works\n",
        "MODEL_ID = \"gemini-robotics-er-1.5-preview\"\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "print(\n",
        "    client.models.generate_content(\n",
        "        model=MODEL_ID, contents=\"Are you there?\"\n",
        "    ).text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pytVkhMqtfnN"
      },
      "source": [
        "Many of the examples use the same recipe - an image, a prompt, and a `GenerateContentConfig`. These functions will help reduce code duplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHcUncwNtL-v"
      },
      "outputs": [],
      "source": [
        "# Resizing to speed-up rendering\n",
        "def get_image_resized(img_path):\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize(\n",
        "        (800, int(800 * img.size[1] / img.size[0])), Image.Resampling.LANCZOS\n",
        "    )\n",
        "    return img\n",
        "\n",
        "\n",
        "def call_gemini_robotics_er(img, prompt, config=None):\n",
        "    if config is None:\n",
        "        config = types.GenerateContentConfig(\n",
        "           temperature=0.5, thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
        "        )\n",
        "\n",
        "    image_response = client.models.generate_content(\n",
        "          model=MODEL_ID,\n",
        "          contents=[img, prompt],\n",
        "          config=config,\n",
        "    )\n",
        "\n",
        "    print(image_response.text)\n",
        "\n",
        "    return parse_json(image_response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPDvMJz6dGhd"
      },
      "source": [
        "# 2D Pointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KBX_F0adKQ5"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/aloha-arms-table.png -O aloha-arms-table.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/gameboard.png -O gameboard.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/washers.png -O washer.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/aloha-pen.gif -O aloha-pen.gif -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqFpIQbtdbjE"
      },
      "outputs": [],
      "source": [
        "# @title Pointing to Undefined Objects\n",
        "\n",
        "img = get_image_resized(\"aloha-arms-table.png\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Point to no more than 10 items in the image. The label returned should be an\n",
        "    identifying name for the object detected.\n",
        "\n",
        "    The answer should follow the JSON format:\n",
        "    [{\"point\": <point>, \"label\": <label1>}, ...]\n",
        "\n",
        "    The points are in [y, x] format normalized to 0-1000.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88XlG1f8-uH_"
      },
      "outputs": [],
      "source": [
        "# @title Pointing to Defined Objects\n",
        "\n",
        "img = get_image_resized(\"aloha-arms-table.png\")\n",
        "\n",
        "queries = [\n",
        "    \"bread\",\n",
        "    \"starfruit\",\n",
        "    \"banana\",\n",
        "]\n",
        "\n",
        "prompt = textwrap.dedent(f\"\"\"\\\n",
        "Get all points matching the following objects: {', '.join(queries)}. The label\n",
        "returned should be an identifying name for the object detected.\n",
        "\n",
        "The answer should follow the JSON format:\n",
        "[{{\"point\": <point>, \"label\": <label1>}}, ...]\n",
        "\n",
        "The points are in [y, x] format normalized to 0-1000.\n",
        "\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "points_data = []\n",
        "try:\n",
        "  data = json.loads(json_output)\n",
        "  points_data.extend(data)\n",
        "except json.JSONDecodeError:\n",
        "  print(\"Warning: Invalid JSON response. Skipping.\")\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json.dumps(points_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Vdb0xW3djfd"
      },
      "outputs": [],
      "source": [
        "# @title Point to all instances of an object based on more abstract description (e.g. \"fruit\")\n",
        "\n",
        "points_data = []\n",
        "img = get_image_resized(\"aloha-arms-table.png\")\n",
        "\n",
        "prompt = textwrap.dedent(f\"\"\"\\\n",
        "        Get all points for fruit. The label returned should be an identifying\n",
        "        name for the object detected.\n",
        "\n",
        "        The answer should follow the json format:\n",
        "        [{{\"point\": <point>, \"label\": <label1>}}, ...]\n",
        "\n",
        "        The points are in [y, x] format normalized to 0-1000.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "try:\n",
        "  data = json.loads(json_output)\n",
        "  points_data.extend(data)\n",
        "except json.JSONDecodeError:\n",
        "  print(f\"Warning: Invalid JSON response, skipping.\")\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json.dumps(points_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqapTqtbdw3c"
      },
      "outputs": [],
      "source": [
        "# @title Point to all instances of an object\n",
        "\n",
        "points_data = []\n",
        "img = get_image_resized(\"gameboard.png\")\n",
        "\n",
        "queries = [\n",
        "    \"game board slot\",\n",
        "    \"X game piece\",\n",
        "]\n",
        "\n",
        "start_time = time.time()\n",
        "for obj in queries:\n",
        "  prompt = textwrap.dedent(f\"\"\"\\\n",
        "      Get all points matching {obj}. The label returned should be an identifying\n",
        "      name for the object detected.\n",
        "\n",
        "      The answer should follow the JSON format:\n",
        "      [{{\"point\": <point>, \"label\": <label1>}}, ...]\n",
        "\n",
        "      The points are in [y, x] format normalized to 0-1000.\"\"\")\n",
        "  json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "  try:\n",
        "    data = json.loads(json_output)\n",
        "    points_data.extend(data)\n",
        "  except json.JSONDecodeError:\n",
        "    print(f\"Warning: Invalid JSON response for {obj}. Skipping.\")\n",
        "    continue\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json.dumps(points_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3jMpkXndyfa"
      },
      "outputs": [],
      "source": [
        "# @title Pointing to certain parts of an object in serial\n",
        "img = get_image_resized(\"aloha-arms-table.png\")\n",
        "points_data = []\n",
        "\n",
        "queries = [\n",
        "    (\"paper bag\", \"handles\"),\n",
        "    (\"banana\", \"the stem\"),\n",
        "    (\"banana\", \"center\"),\n",
        "    (\"starfruit\", \"center\"),\n",
        "    (\"lime\", \"center\"),\n",
        "    (\"light blue bowl\", \"rim\"),\n",
        "    (\"dark blue bowl\", \"rim\"),\n",
        "    (\"measuring cup\", \"rim\"),\n",
        "    (\"measuring cup\", \"handle\"),\n",
        "    (\"bowl\", \"tomato\"),\n",
        "]\n",
        "\n",
        "start_time = time.time()\n",
        "for obj, part in queries:\n",
        "  prompt = POINT_PROMPT_TEMPLATE.replace(\"$object\", obj).replace(\"$part\", part)\n",
        "\n",
        "  json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "  try:\n",
        "    data = json.loads(json_output)\n",
        "    points_data.extend(data)\n",
        "  except json.JSONDecodeError:\n",
        "    print(f\"Warning: Invalid JSON response for {obj}, {part}. Skipping.\")\n",
        "    continue\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json.dumps(points_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thIJjmAKd0yG"
      },
      "source": [
        "As you can see in the example above, pointing to these objects in a loop can take a moment (e.g. 15 seconds). When possible, it is recommended that you run your queries in parallel to improve response time, as you can see in the following example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmLtTiWSd16y"
      },
      "outputs": [],
      "source": [
        "# @title Pointing to certain parts of an object in parallel\n",
        "\n",
        "img = get_image_resized(\"aloha-arms-table.png\")\n",
        "points_data = []\n",
        "\n",
        "queries = [\n",
        "    (\"paper bag\", \"handles\"),\n",
        "    (\"banana\", \"the stem\"),\n",
        "    (\"banana\", \"center\"),\n",
        "    (\"starfruit\", \"center\"),\n",
        "    (\"lime\", \"center\"),\n",
        "    (\"light blue bowl\", \"rim\"),\n",
        "    (\"dark blue bowl\", \"rim\"),\n",
        "    (\"measuring cup\", \"rim\"),\n",
        "    (\"measuring cup\", \"handle\"),\n",
        "    (\"bowl\", \"tomato\"),\n",
        "]\n",
        "\n",
        "def process_query(obj, part):\n",
        "  prompt = POINT_PROMPT_TEMPLATE.replace(\"$object\", obj).replace(\"$part\", part)\n",
        "  json_output = call_gemini_robotics_er(img, prompt)\n",
        "  try:\n",
        "    data = json.loads(json_output)\n",
        "    return data\n",
        "  except json.JSONDecodeError:\n",
        "    print(f\"Warning: Invalid JSON response for {obj}, {part}. Skipping.\")\n",
        "    return []\n",
        "\n",
        "start_time = time.time()\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "  results = executor.map(\n",
        "      lambda query: process_query(query[0], query[1]), queries\n",
        "  )\n",
        "\n",
        "for result in results:\n",
        "  points_data.extend(result)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json.dumps(points_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O8QCm1Pd3le"
      },
      "outputs": [],
      "source": [
        "# @title Counting by Pointing\n",
        "\n",
        "img = get_image_resized(\"washer.png\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Point to each washer in the box. Return the answer in the format:\n",
        "    [{\"point\": <point>, \"label\": <label1>}, ...]\n",
        "\n",
        "    The points are in [y, x] format normalized to 0-1000.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "try:\n",
        "  data = json.loads(json_output)\n",
        "  print(f\"count: {len(data)}\")\n",
        "except json.JSONDecodeError:\n",
        "  print(\"Error: Could not decode JSON response from the model.\")\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah7f2SZuYZYi"
      },
      "outputs": [],
      "source": [
        "# @title Pointing to Defined Objects in a GIF\n",
        "\n",
        "gif_path = \"aloha-pen.gif\"\n",
        "try:\n",
        "  gif = Image.open(gif_path)\n",
        "  print(f\"Successfully loaded GIF: {gif_path}\")\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: GIF file not found at {gif_path}\")\n",
        "  raise\n",
        "\n",
        "frames = extract_frames(gif)\n",
        "\n",
        "# Define the objects to query\n",
        "queries = [\n",
        "    \"pen (on desk)\",\n",
        "    \"pen (in robot hand)\",\n",
        "    \"laptop (opened)\",\n",
        "    \"laptop (closed)\",\n",
        "]\n",
        "\n",
        "prompt = textwrap.dedent(f\"\"\"\\\n",
        "Point to the following objects in the provided image: {\", \".join(queries)}.\n",
        "\n",
        "The answer should follow the JSON format:\n",
        "[{{\"point\": <point>, \"label\": <label1>}}, ...]\n",
        "\n",
        "The points are in [y, x] format normalized to 0-1000.\n",
        "\n",
        "If no objects are found, return an empty JSON list [].\"\"\")\n",
        "\n",
        "\n",
        "# Send every 10th frame as a separate request for the sake of time\n",
        "analyzed_frames_data = []\n",
        "frame_step = 10\n",
        "\n",
        "for i in range(0, len(frames), frame_step):\n",
        "  frame_index = i\n",
        "  frame = frames[frame_index]\n",
        "  print(f\"Processing frame {frame_index+1}/{len(frames)}...\")\n",
        "\n",
        "  try:\n",
        "    image_response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=[frame, prompt],\n",
        "        config=types.GenerateContentConfig(\n",
        "            temperature=0.5,\n",
        "            thinking_config=types.ThinkingConfig(thinking_budget=0),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    try:\n",
        "      json_output = parse_json(image_response.text)\n",
        "      frame_points = json.loads(json_output)\n",
        "      analyzed_frames_data.append(frame_points)\n",
        "      print(\n",
        "          f\"  Successfully parsed {len(frame_points)} points for frame\"\n",
        "          f\" {frame_index+1}.\"\n",
        "      )\n",
        "    except json.JSONDecodeError as e:\n",
        "      print(\n",
        "          f\"  Error decoding JSON for frame {frame_index+1}: {e}. Appending\"\n",
        "          \" empty list.\"\n",
        "      )\n",
        "      analyzed_frames_data.append([])\n",
        "    except Exception as e:\n",
        "      print(\n",
        "          \"  An unexpected error occurred processing frame\"\n",
        "          f\" {frame_index+1} response: {e}. Appending empty list.\"\n",
        "      )\n",
        "      analyzed_frames_data.append([])\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\n",
        "        f\"  Error generating content for frame {frame_index+1}: {e}. Appending\"\n",
        "        \" empty list.\"\n",
        "    )\n",
        "    analyzed_frames_data.append([])\n",
        "\n",
        "\n",
        "print(f\"Collected point data for {len(analyzed_frames_data)} analyzed frames.\")\n",
        "\n",
        "points_data_all_frames = populate_points_for_all_frames(\n",
        "    len(frames), frame_step, analyzed_frames_data\n",
        ")\n",
        "print(f\"Populated point data for {len(points_data_all_frames)} total frames.\")\n",
        "\n",
        "\n",
        "modified_frames = overlay_points_on_frames(frames, points_data_all_frames)\n",
        "display_gif(modified_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK9IACHTeETV"
      },
      "source": [
        "# Object Detection and Bounding Boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCgpTAPmeG7n"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/aloha-arms-table.png -O aloha-arms-table.png -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ekqe-vceI5O"
      },
      "outputs": [],
      "source": [
        "# @title 2D Bounding boxes\n",
        "\n",
        "img = get_image_resized(\"aloha-arms-table.png\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "      Return bounding boxes as a JSON array with labels. Never return masks or\n",
        "      code fencing. Limit to 25 objects. Include as many objects as you can\n",
        "      identify on the table.\n",
        "      If an object is present multiple times, name them according to their\n",
        "      unique characteristic (colors, size, position, unique characteristics,\n",
        "      etc..).\n",
        "      The format should be as follows:\n",
        "      [{\"box_2d\": [ymin, xmin, ymax, xmax], \"label\": <label for the object>}]\n",
        "      normalized to 0-1000. The values in box_2d must only be integers.\n",
        "\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "\n",
        "plot_bounding_boxes(img, json_output)\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd9n_0kzeRsb"
      },
      "source": [
        "# Trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzUkGwxGeTok"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/aloha_desk.png -O aloha_desk.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/particles.jpg -O particles.jpg -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/livingroom.jpeg -O livingroom.jpeg -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4no_6HBeU-j"
      },
      "outputs": [],
      "source": [
        "# @title Simple Trajectory Planning\n",
        "\n",
        "img = get_image_resized(\"aloha_desk.png\")\n",
        "points_data = []\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Place a point on the red pen, then 15 points for the trajectory of moving\n",
        "    the red pen to the top of the organizer on the left.\n",
        "\n",
        "    The points should be labeled by order of the trajectory, from '0' (start\n",
        "    point at left hand) to <n> (final point).\n",
        "\n",
        "    The answer should follow the JSON format:\n",
        "    [{\"point\": <point>, \"label\": <label1>}, ...]\n",
        "\n",
        "    The points are in [y, x] format normalized to 0-1000.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "config=types.GenerateContentConfig(temperature=0.5)\n",
        "json_output = call_gemini_robotics_er(img, prompt, config)\n",
        "\n",
        "try:\n",
        "  data = json.loads(json_output)\n",
        "  points_data.extend(data)\n",
        "except json.JSONDecodeError:\n",
        "  print(\"Warning: Invalid JSON response. Skipping.\")\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json.dumps(points_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN3aS0kQeXfm"
      },
      "outputs": [],
      "source": [
        "# @title Path for Brushing Particles\n",
        "\n",
        "img = get_image_resized(\"particles.jpg\")\n",
        "points_data = []\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Point to the the blue brush and a list of 10 points covering the region of\n",
        "    particles. Ensure that the points are spread evenly over the particles to\n",
        "    create a smooth trajectory.\n",
        "\n",
        "    Label the points from 1 to 10 based on the order that they should be\n",
        "    approached in the trajectory of cleaning the plate. Movement should start\n",
        "    from the brush.\n",
        "\n",
        "    The answer should follow the JSON format:\n",
        "    [{\"point\": <point>, \"label\": <label1>}, ...]\n",
        "\n",
        "    The points are in [y, x] format normalized to 0-1000.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "config=types.GenerateContentConfig(temperature=0.5)\n",
        "json_output = call_gemini_robotics_er(img, prompt, config)\n",
        "\n",
        "try:\n",
        "  data = json.loads(json_output)\n",
        "  points_data.extend(data)\n",
        "except json.JSONDecodeError:\n",
        "  print(\"Warning: Invalid JSON response. Skipping.\")\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json.dumps(points_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwdO5V2cPkEE"
      },
      "outputs": [],
      "source": [
        "# @title Obstacle-avoidance trajectory planning\n",
        "\n",
        "img = get_image_resized(\"livingroom.jpeg\")\n",
        "points_data = []\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Find the most direct collision-free trajectory of 10 points on the floor\n",
        "    between the current view origin and the green ottoman in the back left.\n",
        "    The points should avoid all other obstacles on the floor.\n",
        "\n",
        "    The answer should follow the JSON format:\n",
        "    [{\"point\": <point>, \"label\": <label1>}, ...]\n",
        "\n",
        "    The points are in [y, x] format normalized to 0-1000.\n",
        "    \"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "config=types.GenerateContentConfig(temperature=0.5)\n",
        "json_output = call_gemini_robotics_er(img, prompt, config)\n",
        "\n",
        "try:\n",
        "  data = json.loads(json_output)\n",
        "  points_data.extend(data)\n",
        "except json.JSONDecodeError:\n",
        "  print(\"Warning: Invalid JSON response. Skipping.\")\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json.dumps(points_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y74wtNdpeqRE"
      },
      "source": [
        "# Spatial Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhP3JnXResEw"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/clear_space.png -O clear_space.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/desk_organization.mp4 -O desk_organization.mp4\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/bookshelf.jpeg -O bookshelf.jpeg -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/cart.png -O cart.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/sockets.jpeg -O sockets.jpeg -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/weights.jpeg -O weights.jpeg -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/lunch.png -O lunch.png -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU4ZTwgdXQeb"
      },
      "outputs": [],
      "source": [
        "# @title Item to remove to make room for laptop\n",
        "\n",
        "img = get_image_resized(\"clear_space.png\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Point to the object that I need to remove to make room for my laptop.\n",
        "\n",
        "    The answer should follow the JSON format:\n",
        "    [{\"point\": <point>, \"label\": <label1>}, ...]\n",
        "\n",
        "    The points are in [y, x] format normalized to 0-1000.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S0jeUGS8Yik"
      },
      "outputs": [],
      "source": [
        "# @title Orchestrating: Packing a Lunch\n",
        "\n",
        "img = get_image_resized(\"lunch.png\")\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Explain how to pack the lunch box and lunch bag. Point to each object that\n",
        "    you refer to.\n",
        "\n",
        "    Each point should be in the format:\n",
        "    [{\"point\": [y, x], \"label\": }]\n",
        "    where the coordinates are normalized between 0-1000.\n",
        "    \"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN9763Z452dG"
      },
      "outputs": [],
      "source": [
        "# @title Empty electrical sockets\n",
        "\n",
        "img = get_image_resized(\"sockets.jpeg\")\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Point to the unobstructed empty sockets.\n",
        "\n",
        "    The answer should follow the JSON format:\n",
        "    [{\"point\": <point>, \"label\": <label1>}, ...]\n",
        "\n",
        "    The points are in [y, x] format normalized to 0-1000.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HV4SOPS3Jc3"
      },
      "outputs": [],
      "source": [
        "# @title Limiting item lift (3LB limit)\n",
        "img = get_image_resized(\"weights.jpeg\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    I am a robot with a payload of 3LBs. Point to all the objects in the image I\n",
        "    am physically able to pick up.\n",
        "\n",
        "    The answer should follow the JSON format:\n",
        "    [{\"point\": <point>, \"label\": <label1>}, ...]\n",
        "\n",
        "    The points are in [y, x] format normalized to 0-1000.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "config=types.GenerateContentConfig(\n",
        "    temperature=0.5,\n",
        "    thinking_config=types.ThinkingConfig(thinking_budget=-1),\n",
        ")\n",
        "json_output = call_gemini_robotics_er(img, prompt, config)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NJNi60l6UlK"
      },
      "outputs": [],
      "source": [
        "# @title Video Analysis\n",
        "\n",
        "myfile = client.files.upload(file=\"/content/desk_organization.mp4\")\n",
        "while myfile.state == \"PROCESSING\":\n",
        "  print(\".\", end=\"\")\n",
        "  time.sleep(1)\n",
        "  myfile = client.files.get(name=myfile.name)\n",
        "\n",
        "if myfile.state.name == \"FAILED\":\n",
        "  raise ValueError(myfile.state.name)\n",
        "\n",
        "print(\"Uploaded\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Describe in detail each step of finishing the task. Breaking it down by\n",
        "    timestamp, output in JSON format with keys \"start_timestamp\",\n",
        "    \"end_timestamp\" and \"description\".\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[myfile, prompt],\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=0.5,\n",
        "        thinking_config=types.ThinkingConfig(thinking_budget=-1),\n",
        "    ),\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"\\nTotal processing time: {elapsed_time:.4f} seconds\")\n",
        "\n",
        "print(response.text)\n",
        "\n",
        "video_widget = widgets.Video.from_file(\"/content/desk_organization.mp4\")\n",
        "display.display(video_widget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eXAWLyiaiXy"
      },
      "outputs": [],
      "source": [
        "# @title Video Analysis: Time Range\n",
        "\n",
        "conversation_history = [\n",
        "    {\"role\": \"user\", \"parts\": [{\"text\": prompt}]},\n",
        "    {\"role\": \"model\", \"parts\": [{\"text\": response.text}]},\n",
        "]\n",
        "\n",
        "chat = client.chats.create(model=MODEL_ID, history=conversation_history)\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Zoom into second 15 to 22 and provide a per-second breakdown of what is\n",
        "    happening in the same format.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "response = chat.send_message([prompt, myfile])\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"\\nTotal processing time: {elapsed_time:.4f} seconds\")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7jL2EKfe20o"
      },
      "outputs": [],
      "source": [
        "# @title Finding the fourth row of shelves\n",
        "\n",
        "img = get_image_resized(\"bookshelf.jpeg\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Return bounding boxes as a JSON array with labels highlighting all cubbies\n",
        "    in the fourth row of shelves.\n",
        "\n",
        "    The format should be as follows:\n",
        "    [{\"box_2d\": [ymin, xmin, ymax, xmax], \"label\": <label for the object>}]\n",
        "\n",
        "    normalized to 0-1000. The values in box_2d must only be integers.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "config=types.GenerateContentConfig(temperature=0.5)\n",
        "json_output = call_gemini_robotics_er(img, prompt, config)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "plot_bounding_boxes(img, json_output)\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7uOXX7Ce4Ot"
      },
      "outputs": [],
      "source": [
        "# @title Finding shelves with specific items\n",
        "\n",
        "img = get_image_resized(\"bookshelf.jpeg\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    \"I need to blow my nose.\"\n",
        "    Find the cubby that can help.\n",
        "\n",
        "    The format should be as follows:\n",
        "    [{\"box_2d\": [ymin, xmin, ymax, xmax], \"label\": <label for the object>}]\n",
        "\n",
        "    normalized to 0-1000. The values in box_2d must only be integers.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "config=types.GenerateContentConfig(temperature=0.5)\n",
        "json_output = call_gemini_robotics_er(img, prompt, config)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "plot_bounding_boxes(img, json_output)\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGTa8Jvdw3AR"
      },
      "outputs": [],
      "source": [
        "# @title Counting items with thinking\n",
        "\n",
        "img = get_image_resized(\"cart.png\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    How many items are inside of the cart basket?\n",
        "    Please share your reasoning.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "config=types.GenerateContentConfig(temperature=0.5)\n",
        "json_output = call_gemini_robotics_er(img, prompt, config)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMwl91mQBgqe"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/initial_state_1.png -O initial_state_1.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/initial_state_2.png -O initial_state_2.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/initial_state_3.png -O initial_state_3.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/initial_state_4.png -O initial_state_4.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/current_state_1.png -O current_state_1.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/current_state_2.png -O current_state_2.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/current_state_3.png -O current_state_3.png -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/current_state_4.png -O current_state_4.png -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O57mlUujulDq"
      },
      "outputs": [],
      "source": [
        "# @title Multi-view correspondence and Success Detection\n",
        "\n",
        "initial_state_1 = Image.open(\"initial_state_1.png\")\n",
        "initial_state_2 = Image.open(\"initial_state_2.png\")\n",
        "initial_state_3 = Image.open(\"initial_state_3.png\")\n",
        "initial_state_4 = Image.open(\"initial_state_4.png\")\n",
        "current_state_1 = Image.open(\"current_state_1.png\")\n",
        "current_state_2 = Image.open(\"current_state_2.png\")\n",
        "current_state_3 = Image.open(\"current_state_3.png\")\n",
        "current_state_4 = Image.open(\"current_state_4.png\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    For this task, you will see a robot or human trying to perform the task of\n",
        "    putting the mango into the brown container. You may see multiple camera\n",
        "    views of the same scene. Some cameras are static and are mounted outside of\n",
        "    the scene and some cameras are mounted on the robot arms and thus they are\n",
        "    moving during the episode.\n",
        "\n",
        "    The first 4 images show multiple camera views from the start of the episode\n",
        "    (some time ago). The last 4 images show multiple camera views from the\n",
        "    current moment in the episode (as it is now).\n",
        "\n",
        "    Looking at these images and comparing the start of the episode with current\n",
        "    state did the robot successfully perform the task \"put the mango into the\n",
        "    brown container\"?\n",
        "\n",
        "    Answer only with (1) yes or (2) no. Return the number (1) or (2) that best\n",
        "    answers the question.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        initial_state_1,\n",
        "        initial_state_2,\n",
        "        initial_state_3,\n",
        "        initial_state_4,\n",
        "        current_state_1,\n",
        "        current_state_2,\n",
        "        current_state_3,\n",
        "        current_state_4,\n",
        "        prompt\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(temperature=0.5),\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"\\nTotal processing time: {elapsed_time:.4f} seconds\")\n",
        "print(f\"Success? {'Yes' if response.text == '(1)' else 'No'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_bjl2oglZPY"
      },
      "source": [
        "# Code Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaAEwd8j4Ki8"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/air_quality.jpeg -O air_quality.jpeg -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa5RGtAUhBbp"
      },
      "outputs": [],
      "source": [
        "# @title Zooming in on sections of an image for better readings\n",
        "\n",
        "img = get_image_resized(\"air_quality.jpeg\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    What is the air quality reading? Using the code execution feature, zoom in\n",
        "    on the image to take a closer look.\"\"\")\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[img, prompt],\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=0.5,\n",
        "        tools=[types.Tool(code_execution=types.ToolCodeExecution)],\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "  if part.text is not None:\n",
        "    print(part.text)\n",
        "  if part.executable_code is not None:\n",
        "    print(part.executable_code.code)\n",
        "  if part.code_execution_result is not None:\n",
        "    print(part.code_execution_result.output)\n",
        "\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD5cDm3jCrwH"
      },
      "source": [
        "# Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIYq0-LSCvw8"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/mango.png -O mango.png -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaCtmnp1UOMp"
      },
      "outputs": [],
      "source": [
        "# @title Segmentation with robot gripper and item\n",
        "\n",
        "img = get_image_resized(\"mango.png\")\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Provide the segmentation masks for the following objects in this image:\n",
        "    mango, left robot gripper finger, right robot gripper finger.\n",
        "\n",
        "    The answer should follow the JSON format:\n",
        "    [\n",
        "      {\n",
        "        \"box_2d\": [ymin, xmin, ymax, xmax],\n",
        "        \"label\": \"<label for the object>\",\n",
        "        \"mask\": \"data:image/png;base64,<base64 encoded PNG mask>\"\n",
        "      },\n",
        "      ...\n",
        "    ]\n",
        "\n",
        "    The box_2d coordinates should be normalized to 0-1000 and must be integers.\n",
        "    The mask should be a base64 encoded PNG image where non-zero pixels indicate\n",
        "    the mask.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "config=types.GenerateContentConfig(temperature=0.5)\n",
        "print(\"Raw Model Response Text:\")\n",
        "json_output = call_gemini_robotics_er(img, prompt, config)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "\n",
        "try:\n",
        "  segmentation_masks = parse_segmentation_masks(\n",
        "      json_output, img_height=img.size[1], img_width=img.size[0]\n",
        "  )\n",
        "  print(f\"Successfully parsed {len(segmentation_masks)} segmentation masks.\")\n",
        "\n",
        "  annotated_img = plot_segmentation_masks(\n",
        "      img.convert(\"RGBA\"), segmentation_masks\n",
        "  )\n",
        "  display.display(annotated_img)\n",
        "\n",
        "except json.JSONDecodeError as e:\n",
        "  print(f\"Error decoding JSON response: {e}\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred during mask processing or plotting: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MQzDeWjJVpu"
      },
      "source": [
        "# Task Orchestration\n",
        "\n",
        "To demonstrate task orchestration with your own custom robot API, this example will introduce a mock API that can be used for a simple pick-and-place operation. Both the block and the container where the block should be placed will be located and highlighted, and then the series of functions provided to the API will be called with appropriate logic for performing the action. This will use an origin system with 0,0 in a corner rather than on the robot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNYGjW5rJy3c"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/robotics/er-1-5-example-colab/soarm-block.png -O soarm-block.png -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRTLVVEJJYoI"
      },
      "outputs": [],
      "source": [
        "# @title Locate relevant objects\n",
        "\n",
        "img = get_image_resized(\"soarm-block.png\")\n",
        "points_data = []\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "    Locate and point to the blue block and the orange bowl. The label returned\n",
        "    should be an identifying name for the object detected.\n",
        "\n",
        "    The answer should follow the JSON format:\n",
        "    [{\"point\": <point>, \"label\": <label1>}, ...]\n",
        "\n",
        "    The points are in [y, x] format normalized to 0-1000.\"\"\")\n",
        "\n",
        "start_time = time.time()\n",
        "json_output = call_gemini_robotics_er(img, prompt)\n",
        "\n",
        "data = json.loads(json_output)\n",
        "points_data.extend(data)\n",
        "\n",
        "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n",
        "IPython.display.HTML(generate_point_html(img, json_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChFtc8PhSs64"
      },
      "outputs": [],
      "source": [
        "# @title Use location of relevant objects to call functions and perform pick-and-place\n",
        "\n",
        "# Define the robot's origin point so coordinates can be based on robot location\n",
        "# for movements rather than original origin from the corner.\n",
        "\n",
        "def move(x, y, high):\n",
        "  print(f\"moving to coordinates: {x}, {y}, {15 if high else 5}\")\n",
        "\n",
        "\n",
        "def setGripperState(opened):\n",
        "  print(\"Opening gripper\" if opened else \"Closing gripper\")\n",
        "\n",
        "\n",
        "def returnToOrigin():\n",
        "  print(\"Returning to origin pose\")\n",
        "\n",
        "\n",
        "robot_origin_y = 300\n",
        "robot_origin_x = 500\n",
        "\n",
        "blue_block_point = None\n",
        "orange_bowl_point = None\n",
        "\n",
        "for item in points_data:\n",
        "  if item.get(\"label\") == \"blue block\":\n",
        "    blue_block_point = item.get(\"point\")\n",
        "  elif item.get(\"label\") == \"orange bowl\":\n",
        "    orange_bowl_point = item.get(\"point\")\n",
        "\n",
        "if blue_block_point and orange_bowl_point:\n",
        "  block_y, block_x = blue_block_point\n",
        "  bowl_y, bowl_x = orange_bowl_point\n",
        "\n",
        "  print(f\"Blue block normalized coordinates (y, x): {block_y}, {block_x}\")\n",
        "  print(f\"Orange bowl normalized coordinates (y, x): {bowl_y}, {bowl_x}\")\n",
        "\n",
        "  block_relative_x = block_x - robot_origin_x\n",
        "  block_relative_y = block_y - robot_origin_y\n",
        "  bowl_relative_x = bowl_x - robot_origin_x\n",
        "  bowl_relative_y = bowl_y - robot_origin_y\n",
        "\n",
        "  prompt = textwrap.dedent(f\"\"\"\\\n",
        "      You are a robotic arm with six degrees-of-freedom. You have the following\n",
        "      functions available to you:\n",
        "\n",
        "      def move(x, y, high):\n",
        "        # Moves the arm to the given coordinates. The boolean value 'high' set\n",
        "        # to True means the robot arm should be lifted above the scene for\n",
        "        # avoiding obstacles during motion. 'high' set to False means the robot\n",
        "        # arm should have the gripper placed on the surface for interacting with\n",
        "        # objects.\n",
        "\n",
        "      def setGripperState(opened):\n",
        "        # Opens the gripper if opened set to true, otherwise closes the gripper\n",
        "\n",
        "      def returnToOrigin():\n",
        "        # Returns the robot to an initial state. Should be called as a cleanup\n",
        "        # operation.\n",
        "\n",
        "      The origin point for calculating the moves is at normalized point\n",
        "      y={robot_origin_y}, x={robot_origin_x}. Use this as the new (0,0) for\n",
        "      calculating moves, allowing x and y to be negative.\n",
        "\n",
        "      Perform a pick and place operation where you pick up the blue block at\n",
        "      normalized coordinates ({block_x}, {block_y}) (relative coordinates:\n",
        "      {block_relative_x}, {block_relative_y}) and place it into the orange bowl\n",
        "      at normalized coordinates ({bowl_x}, {bowl_y}) (relative coordinates:\n",
        "      {bowl_relative_x}, {bowl_relative_y}).\n",
        "      Provide the sequence of function calls as a JSON list of objects, where\n",
        "      each object has a \"function\" key (the function name) and an \"args\" key\n",
        "      (a list of arguments for the function).\n",
        "\n",
        "      Also, include your reasoning before the JSON output.\n",
        "\n",
        "      For example:\n",
        "      Reasoning: To pick up the block, I will first move the arm to a high\n",
        "      position above the block, open the gripper, move down to the block, close\n",
        "      the gripper, lift the arm, move to a high position above the bowl, move\n",
        "      down to the bowl, open the gripper, and then lift the arm back to a high\n",
        "      position.\"\"\")\n",
        "\n",
        "  start_time = time.time()\n",
        "  config=types.GenerateContentConfig(temperature=0.5)\n",
        "  print(\"Model Response:\")\n",
        "  json_output = call_gemini_robotics_er(img, prompt, config)\n",
        "\n",
        "  try:\n",
        "    function_calls = json.loads(json_output)\n",
        "\n",
        "    print(\"\\nExecuting Function Calls:\")\n",
        "    for call in function_calls:\n",
        "      function_name = call.get(\"function\")\n",
        "      arguments = call.get(\"args\", [])\n",
        "\n",
        "      if function_name == \"move\":\n",
        "        move(*arguments)\n",
        "      elif function_name == \"setGripperState\":\n",
        "        setGripperState(*arguments)\n",
        "      elif function_name == \"returnToOrigin\":\n",
        "        returnToOrigin()\n",
        "      else:\n",
        "        print(f\"Unknown function: {function_name}\")\n",
        "\n",
        "  except json.JSONDecodeError:\n",
        "    print(\"Error: Could not parse JSON response from the model.\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during function execution: {e}\")\n",
        "\n",
        "else:\n",
        "  print(\"Could not find coordinates for both blue block and orange bowl.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "gemini-robotics-er.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
