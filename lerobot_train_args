usage: lerobot_train.py [-h] [--config_path str] [--dataset str]
                        [--dataset.repo_id str] [--dataset.root str]
                        [--dataset.episodes str] [--image_transforms str]
                        [--dataset.image_transforms.enable str]
                        [--dataset.image_transforms.max_num_transforms str]
                        [--dataset.image_transforms.random_order str]
                        [--dataset.image_transforms.tfs str]
                        [--dataset.revision str]
                        [--dataset.use_imagenet_stats str]
                        [--dataset.video_backend str]
                        [--dataset.streaming str] [--env str]
                        [--env.type {aloha,pusht,gym_manipulator,libero,metaworld,isaaclab_arena}]
                        [--env.visualization_width str]
                        [--env.visualization_height str] [--robot str]
                        [--env.robot.type str] [--teleop str]
                        [--env.teleop.type str] [--processor str]
                        [--env.processor.control_mode str] [--observation str]
                        [--env.processor.observation.add_joint_velocity_to_observation str]
                        [--env.processor.observation.add_current_to_observation str]
                        [--env.processor.observation.add_ee_pose_to_observation str]
                        [--env.processor.observation.display_cameras str]
                        [--image_preprocessing str]
                        [--env.processor.image_preprocessing.crop_params_dict str]
                        [--env.processor.image_preprocessing.resize_size str]
                        [--gripper str]
                        [--env.processor.gripper.use_gripper str]
                        [--env.processor.gripper.gripper_penalty str]
                        [--reset str]
                        [--env.processor.reset.fixed_reset_joint_positions str]
                        [--env.processor.reset.reset_time_s str]
                        [--env.processor.reset.control_time_s str]
                        [--env.processor.reset.terminate_on_success str]
                        [--inverse_kinematics str]
                        [--env.processor.inverse_kinematics.urdf_path str]
                        [--env.processor.inverse_kinematics.target_frame_name str]
                        [--env.processor.inverse_kinematics.end_effector_bounds str]
                        [--env.processor.inverse_kinematics.end_effector_step_sizes str]
                        [--reward_classifier str]
                        [--env.processor.reward_classifier.pretrained_path str]
                        [--env.processor.reward_classifier.success_threshold str]
                        [--env.processor.reward_classifier.success_reward str]
                        [--env.processor.max_gripper_pos str] [--env.name str]
                        [--env.task_ids str] [--env.camera_name str]
                        [--env.init_states str]
                        [--env.camera_name_mapping str]
                        [--env.observation_height str]
                        [--env.observation_width str] [--env.control_mode str]
                        [--env.obs_type str] [--env.render_mode str]
                        [--env.multitask_eval str] [--env.task str]
                        [--env.fps str] [--env.features str]
                        [--env.features_map str]
                        [--env.max_parallel_tasks str]
                        [--env.disable_env_checker str] [--env.hub_path str]
                        [--env.episode_length str] [--env.num_envs str]
                        [--env.embodiment str] [--env.object str]
                        [--env.mimic str] [--env.teleop_device str]
                        [--env.seed str] [--env.device str]
                        [--env.disable_fabric str] [--env.enable_cameras str]
                        [--env.headless str] [--env.enable_pinocchio str]
                        [--env.environment str] [--env.state_dim str]
                        [--env.action_dim str] [--env.camera_height str]
                        [--env.camera_width str] [--env.video str]
                        [--env.video_length str] [--env.video_interval str]
                        [--env.state_keys str] [--env.camera_keys str]
                        [--env.kwargs str] [--policy str]
                        [--policy.type {act,diffusion,groot,pi0,pi0_fast,pi05,smolvla,tdmpc,vqbet,wall_x,xvla,sac,reward_classifier,sarm}]
                        [--policy.replace_final_stride_with_dilation str]
                        [--policy.pre_norm str] [--policy.dim_model str]
                        [--policy.n_heads str] [--policy.dim_feedforward str]
                        [--policy.feedforward_activation str]
                        [--policy.n_encoder_layers str]
                        [--policy.n_decoder_layers str] [--policy.use_vae str]
                        [--policy.n_vae_encoder_layers str]
                        [--policy.temporal_ensemble_coeff str]
                        [--policy.kl_weight str]
                        [--policy.optimizer_lr_backbone str]
                        [--policy.use_separate_rgb_encoder_per_camera str]
                        [--policy.down_dims str] [--policy.kernel_size str]
                        [--policy.n_groups str]
                        [--policy.diffusion_step_embed_dim str]
                        [--policy.use_film_scale_modulation str]
                        [--policy.noise_scheduler_type str]
                        [--policy.num_train_timesteps str]
                        [--policy.beta_schedule str] [--policy.beta_start str]
                        [--policy.beta_end str] [--policy.prediction_type str]
                        [--policy.clip_sample str]
                        [--policy.clip_sample_range str]
                        [--policy.do_mask_loss_for_padding str]
                        [--policy.scheduler_name str]
                        [--policy.image_size str]
                        [--policy.base_model_path str]
                        [--policy.tokenizer_assets_repo str]
                        [--policy.embodiment_tag str] [--policy.tune_llm str]
                        [--policy.tune_visual str]
                        [--policy.tune_projector str]
                        [--policy.tune_diffusion_model str]
                        [--policy.lora_rank str] [--policy.lora_alpha str]
                        [--policy.lora_dropout str]
                        [--policy.lora_full_model str]
                        [--policy.warmup_ratio str] [--policy.use_bf16 str]
                        [--policy.video_backend str]
                        [--policy.balance_dataset_weights str]
                        [--policy.balance_trajectory_weights str]
                        [--policy.dataset_paths str] [--policy.output_dir str]
                        [--policy.save_steps str] [--policy.max_steps str]
                        [--policy.dataloader_num_workers str]
                        [--policy.report_to str] [--policy.resume str]
                        [--policy.max_action_tokens str]
                        [--policy.text_tokenizer_name str]
                        [--policy.action_tokenizer_name str]
                        [--policy.temperature str]
                        [--policy.max_decoding_steps str]
                        [--policy.fast_skip_tokens str]
                        [--policy.validate_action_token_prefix str]
                        [--policy.use_kv_cache str]
                        [--policy.paligemma_variant str]
                        [--policy.action_expert_variant str]
                        [--policy.num_inference_steps str]
                        [--policy.time_sampling_beta_alpha str]
                        [--policy.time_sampling_beta_beta str]
                        [--policy.time_sampling_scale str]
                        [--policy.time_sampling_offset str]
                        [--policy.image_resolution str]
                        [--policy.gradient_checkpointing str]
                        [--policy.compile_model str]
                        [--policy.compile_mode str]
                        [--policy.adapt_to_pi_aloha str]
                        [--policy.use_delta_joint_actions_aloha str]
                        [--policy.num_steps str] [--policy.use_cache str]
                        [--policy.train_expert_only str]
                        [--policy.train_state_proj str]
                        [--policy.vlm_model_name str]
                        [--policy.load_vlm_weights str]
                        [--policy.add_image_special_tokens str]
                        [--policy.attention_mode str]
                        [--policy.prefix_length str]
                        [--policy.num_expert_layers str]
                        [--policy.num_vlm_layers str]
                        [--policy.self_attn_every_n_layers str]
                        [--policy.expert_width_multiplier str]
                        [--policy.min_period str] [--policy.max_period str]
                        [--rtc_config str] [--policy.rtc_config.enabled str]
                        [--policy.rtc_config.prefix_attention_schedule str]
                        [--policy.rtc_config.max_guidance_weight str]
                        [--policy.rtc_config.execution_horizon str]
                        [--policy.rtc_config.debug str]
                        [--policy.rtc_config.debug_maxlen str]
                        [--policy.n_action_repeats str] [--policy.horizon str]
                        [--policy.q_ensemble_size str] [--policy.mlp_dim str]
                        [--policy.use_mpc str] [--policy.cem_iterations str]
                        [--policy.max_std str] [--policy.min_std str]
                        [--policy.n_gaussian_samples str]
                        [--policy.n_pi_samples str]
                        [--policy.uncertainty_regularizer_coeff str]
                        [--policy.n_elites str]
                        [--policy.elite_weighting_temperature str]
                        [--policy.gaussian_mean_momentum str]
                        [--policy.max_random_shift_ratio str]
                        [--policy.reward_coeff str]
                        [--policy.expectile_weight str]
                        [--policy.value_coeff str]
                        [--policy.consistency_coeff str]
                        [--policy.advantage_scaling str]
                        [--policy.pi_coeff str]
                        [--policy.temporal_decay_coeff str]
                        [--policy.target_model_momentum str]
                        [--policy.n_action_pred_token str]
                        [--policy.action_chunk_size str]
                        [--policy.vision_backbone str]
                        [--policy.crop_shape str]
                        [--policy.crop_is_random str]
                        [--policy.pretrained_backbone_weights str]
                        [--policy.use_group_norm str]
                        [--policy.spatial_softmax_num_keypoints str]
                        [--policy.n_vqvae_training_steps str]
                        [--policy.vqvae_n_embed str]
                        [--policy.vqvae_embedding_dim str]
                        [--policy.vqvae_enc_hidden_dim str]
                        [--policy.gpt_block_size str]
                        [--policy.gpt_input_dim str]
                        [--policy.gpt_output_dim str]
                        [--policy.gpt_n_layer str] [--policy.gpt_n_head str]
                        [--policy.gpt_hidden_dim str]
                        [--policy.offset_loss_weight str]
                        [--policy.primary_code_loss_weight str]
                        [--policy.secondary_code_loss_weight str]
                        [--policy.bet_softmax_temperature str]
                        [--policy.sequentially_select str]
                        [--policy.optimizer_vqvae_lr str]
                        [--policy.optimizer_vqvae_weight_decay str]
                        [--policy.pretrained_name_or_path str]
                        [--policy.action_tokenizer_path str]
                        [--policy.prediction_mode str]
                        [--policy.attn_implementation str]
                        [--policy.chunk_size str]
                        [--policy.n_action_steps str] [--policy.dtype str]
                        [--policy.florence_config str]
                        [--policy.tokenizer_name str]
                        [--policy.tokenizer_max_length str]
                        [--policy.tokenizer_padding_side str]
                        [--policy.pad_language_to str]
                        [--policy.hidden_size str] [--policy.depth str]
                        [--policy.mlp_ratio str] [--policy.num_domains str]
                        [--policy.len_soft_prompts str]
                        [--policy.dim_time str] [--policy.max_len_seq str]
                        [--policy.use_hetero_proj str]
                        [--policy.action_mode str]
                        [--policy.num_denoising_steps str]
                        [--policy.use_proprio str]
                        [--policy.max_action_dim str]
                        [--policy.domain_feature_key str]
                        [--policy.resize_imgs_with_padding str]
                        [--policy.num_image_views str]
                        [--policy.empty_cameras str]
                        [--policy.freeze_language_encoder str]
                        [--policy.train_policy_transformer str]
                        [--policy.train_soft_prompts str]
                        [--policy.optimizer_lr str]
                        [--policy.optimizer_betas str]
                        [--policy.optimizer_eps str]
                        [--policy.optimizer_weight_decay str]
                        [--policy.optimizer_grad_clip_norm str]
                        [--policy.optimizer_soft_prompt_lr_scale str]
                        [--policy.optimizer_soft_prompt_warmup_lr_scale str]
                        [--policy.scheduler_warmup_steps str]
                        [--policy.scheduler_decay_steps str]
                        [--policy.scheduler_decay_lr str]
                        [--policy.dataset_stats str]
                        [--policy.storage_device str]
                        [--policy.vision_encoder_name str]
                        [--policy.freeze_vision_encoder str]
                        [--policy.image_encoder_hidden_dim str]
                        [--policy.shared_encoder str]
                        [--policy.num_discrete_actions str]
                        [--policy.online_steps str]
                        [--policy.online_buffer_capacity str]
                        [--policy.offline_buffer_capacity str]
                        [--policy.async_prefetch str]
                        [--policy.online_step_before_learning str]
                        [--policy.policy_update_freq str]
                        [--policy.discount str]
                        [--policy.temperature_init str]
                        [--policy.num_critics str]
                        [--policy.num_subsample_critics str]
                        [--policy.critic_lr str] [--policy.actor_lr str]
                        [--policy.temperature_lr str]
                        [--policy.critic_target_update_weight str]
                        [--policy.utd_ratio str]
                        [--policy.state_encoder_hidden_dim str]
                        [--policy.target_entropy str]
                        [--policy.use_backup_entropy str]
                        [--critic_network_kwargs str]
                        [--policy.critic_network_kwargs.hidden_dims str]
                        [--policy.critic_network_kwargs.activate_final str]
                        [--policy.critic_network_kwargs.final_activation str]
                        [--actor_network_kwargs str]
                        [--policy.actor_network_kwargs.hidden_dims str]
                        [--policy.actor_network_kwargs.activate_final str]
                        [--policy_kwargs str]
                        [--policy.policy_kwargs.use_tanh_squash str]
                        [--policy.policy_kwargs.std_min str]
                        [--policy.policy_kwargs.std_max str]
                        [--policy.policy_kwargs.init_final str]
                        [--discrete_critic_network_kwargs str]
                        [--policy.discrete_critic_network_kwargs.hidden_dims str]
                        [--policy.discrete_critic_network_kwargs.activate_final str]
                        [--policy.discrete_critic_network_kwargs.final_activation str]
                        [--actor_learner_config str]
                        [--policy.actor_learner_config.learner_host str]
                        [--policy.actor_learner_config.learner_port str]
                        [--policy.actor_learner_config.policy_parameters_push_frequency str]
                        [--policy.actor_learner_config.queue_get_timeout str]
                        [--concurrency str] [--policy.concurrency.actor str]
                        [--policy.concurrency.learner str]
                        [--policy.use_torch_compile str] [--policy.name str]
                        [--policy.num_classes str] [--policy.latent_dim str]
                        [--policy.image_embedding_pooling_dim str]
                        [--policy.dropout_rate str] [--policy.model_name str]
                        [--policy.model_type str] [--policy.num_cameras str]
                        [--policy.learning_rate str]
                        [--policy.weight_decay str]
                        [--policy.grad_clip_norm str]
                        [--policy.n_obs_steps str]
                        [--policy.input_features str]
                        [--policy.output_features str] [--policy.device str]
                        [--policy.use_amp str] [--policy.use_peft str]
                        [--policy.push_to_hub str] [--policy.repo_id str]
                        [--policy.private str] [--policy.tags str]
                        [--policy.license str] [--policy.pretrained_path str]
                        [--policy.annotation_mode str]
                        [--policy.frame_gap str]
                        [--policy.max_rewind_steps str]
                        [--policy.image_dim str] [--policy.text_dim str]
                        [--policy.hidden_dim str] [--policy.num_heads str]
                        [--policy.num_layers str] [--policy.max_state_dim str]
                        [--policy.drop_n_last_frames str]
                        [--policy.batch_size str]
                        [--policy.clip_batch_size str] [--policy.dropout str]
                        [--policy.stage_loss_weight str]
                        [--policy.rewind_probability str]
                        [--policy.language_perturbation_probability str]
                        [--policy.num_sparse_stages str]
                        [--policy.sparse_subtask_names str]
                        [--policy.sparse_temporal_proportions str]
                        [--policy.num_dense_stages str]
                        [--policy.dense_subtask_names str]
                        [--policy.dense_temporal_proportions str]
                        [--policy.pretrained_model_path str]
                        [--policy.image_key str] [--policy.state_key str]
                        [--policy.normalization_mapping str]
                        [--output_dir str] [--job_name str] [--resume str]
                        [--seed str] [--num_workers str] [--batch_size str]
                        [--steps str] [--eval_freq str] [--log_freq str]
                        [--tolerance_s str] [--save_checkpoint str]
                        [--save_freq str] [--use_policy_training_preset str]
                        [--optimizer str]
                        [--optimizer.type {adam,adamw,sgd,xvla-adamw,multi_adam}]
                        [--optimizer.momentum str] [--optimizer.dampening str]
                        [--optimizer.nesterov str] [--optimizer.betas str]
                        [--optimizer.eps str]
                        [--optimizer.soft_prompt_lr_scale str]
                        [--optimizer.soft_prompt_warmup_lr_scale str]
                        [--optimizer.lr str] [--optimizer.weight_decay str]
                        [--optimizer.grad_clip_norm str]
                        [--optimizer.optimizer_groups str] [--scheduler str]
                        [--scheduler.type {diffuser,vqbet,cosine_decay_with_warmup}]
                        [--scheduler.name str]
                        [--scheduler.num_vqvae_training_steps str]
                        [--scheduler.num_cycles str]
                        [--scheduler.num_warmup_steps str]
                        [--scheduler.num_decay_steps str]
                        [--scheduler.peak_lr str] [--scheduler.decay_lr str]
                        [--eval str] [--eval.n_episodes str]
                        [--eval.batch_size str] [--eval.use_async_envs str]
                        [--wandb str] [--wandb.enable str]
                        [--wandb.disable_artifact str] [--wandb.project str]
                        [--wandb.entity str] [--wandb.notes str]
                        [--wandb.run_id str] [--wandb.mode str] [--peft str]
                        [--peft.target_modules str]
                        [--peft.full_training_modules str]
                        [--peft.method_type str] [--peft.init_type str]
                        [--peft.r str] [--use_rabc str]
                        [--rabc_progress_path str] [--rabc_kappa str]
                        [--rabc_epsilon str] [--rabc_head_mode str]
                        [--rename_map str]
lerobot_train.py: error: unrecognized arguments: --push_to_hub=true --hub_model_id=mthirumalai/so101-picknplace1_1

