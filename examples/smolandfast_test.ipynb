{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfec91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from lerobot.datasets.utils import cycle\n",
    "\n",
    "from lerobot.configs.types import FeatureType\n",
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "from lerobot.datasets.utils import dataset_to_policy_features\n",
    "from lerobot.policies.smolandfast.configuration_smolandfast import SMOLANDFASTConfig\n",
    "from lerobot.policies.smolandfast.modeling_smolandfast import SMOLANDFASTPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = Path(\"outputs/train/example_pusht\")\n",
    "output_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"lerobot/pusht_keypoints\"\n",
    "\n",
    "dataset_metadata = LeRobotDatasetMetadata(DATASET_PATH)\n",
    "features = dataset_to_policy_features(dataset_metadata.features)\n",
    "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
    "input_features = {key: ft for key, ft in features.items() if key not in output_features}\n",
    "\n",
    "cfg = SMOLANDFASTConfig(input_features=input_features,\n",
    "                        output_features=output_features)\n",
    "\n",
    "delta_timestamps = {\n",
    "        \"action\": [i / dataset_metadata.fps for i in cfg.action_delta_indices],\n",
    "    }\n",
    "\n",
    "# We can then instantiate the dataset with these delta_timestamps configuration.\n",
    "dataset = LeRobotDataset(DATASET_PATH, delta_timestamps=delta_timestamps)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=0,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    pin_memory=device.type != \"cpu\",\n",
    "    drop_last=True,\n",
    ")\n",
    "dl_iter = cycle(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = SMOLANDFASTPolicy(cfg,\n",
    "                           dataset_stats=dataset_metadata.stats)\n",
    "policy.train()\n",
    "policy.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab062ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dl_iter)\n",
    "\n",
    "for step in tqdm(range(20)):\n",
    "\n",
    "    batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "    loss, _ = policy.forward(batch)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"step: {step} loss: {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b833de",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = policy.normalize_inputs(batch)\n",
    "batch_norm = policy.normalize_targets(batch_norm)\n",
    "\n",
    "decoded_actions = policy.model.generate_actions(batch_norm)\n",
    "error:torch.tensor = torch.sqrt((decoded_actions - batch_norm[\"action\"])**2)\n",
    "\n",
    "print(f\"RMSE {(error.mean(dim=1)*100).tolist()}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359985d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import gym_pusht  # noqa: F401\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "# Create a directory to store the video of the evaluation\n",
    "output_directory = Path(\"outputs/eval/example_pusht_diffusion\")\n",
    "output_directory.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d062bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluation environment to render two observation types:\n",
    "# an image of the scene and state/position of the agent. The environment\n",
    "# also automatically stops running after 300 interactions/steps.\n",
    "env = gym.make(\n",
    "    \"gym_pusht/PushT-v0\",\n",
    "    obs_type=\"environment_state_agent_pos\",\n",
    "    max_episode_steps=300,\n",
    ")\n",
    "\n",
    "# We can verify that the shapes of the features expected by the policy match the ones from the observations\n",
    "# produced by the environment\n",
    "print(policy.config.input_features)\n",
    "print(env.observation_space)\n",
    "\n",
    "# Similarly, we can check that the actions produced by the policy will match the actions expected by the\n",
    "# environment\n",
    "print(policy.config.output_features)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the policy and environments to prepare for rollout\n",
    "policy.reset()\n",
    "numpy_observation, info = env.reset(seed=42)\n",
    "\n",
    "# Prepare to collect every rewards and all the frames of the episode,\n",
    "# from initial state to final state.\n",
    "rewards = []\n",
    "frames = []\n",
    "\n",
    "# Render frame of the initial state\n",
    "frames.append(env.render())\n",
    "\n",
    "step = 0\n",
    "done = False\n",
    "while not done:\n",
    "    # Prepare observation for the policy running in Pytorch\n",
    "    state = torch.from_numpy(numpy_observation[\"agent_pos\"])\n",
    "    env_state = torch.from_numpy(numpy_observation[\"environment_state\"])\n",
    "\n",
    "    # Convert to float32 with image from channel first in [0,255]\n",
    "    # to channel last in [0,1]\n",
    "    state = state.to(torch.float32)\n",
    "    env_state = env_state.to(torch.float32)\n",
    "\n",
    "    # Add extra (empty) batch dimension, required to forward the policy\n",
    "    state = state.unsqueeze(0).unsqueeze(0)\n",
    "    env_state = env_state.unsqueeze(0).unsqueeze(0)\n",
    "    print(state.shape, env_state.shape)\n",
    "\n",
    "    # Create the policy input dictionary\n",
    "    observation = {\n",
    "        \"observation.state\": state,\n",
    "        \"observation.environment_state\": env_state,\n",
    "        \"task\": ['Push the T-shaped block onto the T-shaped target.']\n",
    "    }\n",
    "\n",
    "    # Predict the next action with respect to the current observation\n",
    "    with torch.inference_mode():\n",
    "        action = policy.select_action(observation)\n",
    "\n",
    "    # Prepare the action for the environment\n",
    "    numpy_action = action.squeeze(0).to(\"cpu\").numpy()\n",
    "\n",
    "    # Step through the environment and receive a new observation\n",
    "    numpy_observation, reward, terminated, truncated, info = env.step(numpy_action)\n",
    "    print(f\"{step=} {reward=} {terminated=}\")\n",
    "\n",
    "    # Keep track of all the rewards and frames\n",
    "    rewards.append(reward)\n",
    "    frames.append(env.render())\n",
    "\n",
    "    # The rollout is considered done when the success state is reached (i.e. terminated is True),\n",
    "    # or the maximum number of iterations is reached (i.e. truncated is True)\n",
    "    done = terminated | truncated | done\n",
    "    step += 1\n",
    "\n",
    "if terminated:\n",
    "    print(\"Success!\")\n",
    "else:\n",
    "    print(\"Failure!\")\n",
    "\n",
    "# Get the speed of environment (i.e. its number of frames per second).\n",
    "fps = env.metadata[\"render_fps\"]\n",
    "\n",
    "# Encode all frames into a mp4 video.\n",
    "video_path = output_directory / \"rollout.mp4\"\n",
    "imageio.mimsave(str(video_path), numpy.stack(frames), fps=fps)\n",
    "\n",
    "print(f\"Video of the evaluation is available in '{video_path}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
