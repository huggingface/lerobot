#set
pip install -e /home/hls/codes/lerobot/lerobot_robot_piper
bash can_activate.sh can0 1000000

#tele
lerobot-teleoperate-piper \
  --teleop.type=so101_leader --teleop.port=/dev/ttyACM0 --teleop.use_degrees=false \
  --robot.type=piper --robot.can_interface=can0 --robot.bitrate=1000000 \
  --robot.include_gripper=true --robot.use_degrees=false

#record
lerobot-record-piper \
--teleop.type=so101_leader --teleop.port=/dev/ttyACM0 --teleop.use_degrees=false \
--robot.type=piper --robot.can_interface=can0 --robot.bitrate=1000000 \
--robot.include_gripper=true --robot.use_degrees=false \
--robot.cameras='{"wrist": {"type": "opencv", "index_or_path": 2, "width": 640, "height": 480, "fps": 30, "fourcc": "MJPG"}}' \
--dataset.repo_id local/piper-demo-251110-1 \
--dataset.root /home/hls/datasets/piper-demo-251110-1 \
--dataset.single_task "pick green stem above the red strawberries" \
--dataset.num_episodes=10 \
--dataset.episode_time_s=45 --dataset.reset_time_s=10 \
--dataset.video=true --dataset.push_to_hub=false \
--display_data=true --play_sounds=true

python -m lerobot.async_inference.robot_client \
  --server_address=127.0.0.1:8080 \
  --robot.type=piper \
  --robot.can_interface=can0 \
  --robot.bitrate=1000000 \
  --robot.include_gripper=true --robot.use_degrees=false \
  --robot.cameras="{ laptop: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30, "fourcc": "MJPG"}}" \
  --task="pick green stem above the red strawberries" \
  --policy_type=act \
  --pretrained_name_or_path=act_piper_demo_merged \
  --policy_device=cuda \
  --actions_per_chunk=200 \
  --chunk_size_threshold=0.5 \
  --aggregate_fn_name=weighted_average \
  --debug_visualize_queue_size=True

# Merge train and validation splits back into one dataset
lerobot-edit-dataset \
    --repo_id lerobot/piper_251110 \
    --operation.type merge \
    --operation.repo_ids "['~/datasets/piper_251110', '~/datasets/piper_251110-1']"



python src/lerobot/scripts/lerobot_train.py\
  --dataset.repo_id=local/piper-demo-0 \
  --dataset.root=/home/hls/datasets/piper-demo-0 \
  --dataset.video_backend=pyav \
  --policy.type=pi05 \
  --policy.normalization_mapping='{"ACTION":"MEAN_STD","STATE":"MEAN_STD","VISUAL":"IDENTITY"}' \
  --output_dir=./outputs/pi05_training_run2 \
  --job_name=pi05_training_run2 \
  --policy.repo_id=pi05_sbp \
  --policy.pretrained_path=lerobot/pi05_libero \
  --policy.compile_model=true \
  --policy.gradient_checkpointing=true \
  --wandb.enable=false \
  --policy.dtype=bfloat16 \
  --steps=3000 \
  --policy.device=cuda \
  --batch_size=4


  #ACT#
HF_LEROBOT_HOME=/home/hls/datasets \
HF_HUB_OFFLINE=1 \        # drop if you want to push to the Hub
python src/lerobot/scripts/lerobot_train.py \
  --dataset.repo_id=piper-demo-251110-merged \
  --dataset.root=/home/hls/datasets/piper-demo-251110-merged \
  --policy.type=act \
  --policy.device=cuda \
  --batch_size=8 \
  --steps=10000 \
  --output_dir=./outputs/act_piper_demo_merged \
  --job_name=act_piper_demo_merged \
  --policy.repo_id=piper-demo-act \
  --policy.push_to_hub=false \
  --wandb.enable=false




  python -m lerobot.async_inference.robot_client \
    --server_address=127.0.0.1:8080 \ # SERVER: the host address and port of the policy server
    --robot.type=piper \ # ROBOT: your robot type
    --robot.port=/dev/tty.usbmodem585A0076841 \ # ROBOT: your robot port
    --robot.id=follower_so100 \ # ROBOT: your robot id, to load calibration file
    --robot.cameras="{ laptop: {type: opencv, index_or_path: 0, width: 1920, height: 1080, fps: 30}, phone: {type: opencv, index_or_path: 0, width: 1920, height: 1080, fps: 30}}" \ # POLICY: the cameras used to acquire frames, with keys matching the keys expected by the policy
    --task="dummy" \ # POLICY: The task to run the policy on (`Fold my t-shirt`). Not necessarily defined for all policies, such as `act`
    --policy_type=your_policy_type \ # POLICY: the type of policy to run (smolvla, act, etc)
    --pretrained_name_or_path=user/model \ # POLICY: the model name/path on server to the checkpoint to run (e.g., lerobot/smolvla_base)
    --policy_device=mps \ # POLICY: the device to run the policy on, on the server
    --actions_per_chunk=50 \ # POLICY: the number of actions to output at once
    --chunk_size_threshold=0.5 \ # CLIENT: the threshold for the chunk size before sending a new observation to the server
    --aggregate_fn_name=weighted_average \ # CLIENT: the function to aggregate actions on overlapping portions
    --debug_visualize_queue_size=True # CLIENT: whether to visualize the queue size at runtime


    python -m lerobot_robot_piper.run_act_piper --policy-path /home/hls/codes/lerobot/outputs/act_piper_demo_merged/last/ --dataset-repo-id piper-demo-251110-merged --dataset-root /home/hls/datasets/piper-demo-251110-merged --policy-device cuda --postprocessor-device cuda --can-interface can0 --bitrate 1000000 --include-gripper --use-degrees --loop-frequency 10


python -m lerobot.async_inference.robot_client \
  --server_address 127.0.0.1:8080 \
  --robot.type piper \
  --robot.can_interface can0 \
  --robot.bitrate 1000000 \
  --robot.include_gripper true \
  --robot.use_degrees false \
  --robot.cameras '{"wrist": {"type": "opencv", "index_or_path": 3, "width": 640, "height": 480, "fps": 30, "fourcc": "MJPG"}}' \
  --task "pick green stem above the red strawberries" \
  --policy_type act \
  --pretrained_name_or_path /home/hls/codes/lerobot/outputs/act_piper_demo_merged/checkpoints/010000/pretrained_model \
  --policy_device cuda \
  --actions_per_chunk 200 \
  --chunk_size_threshold 0.5 \
  --aggregate_fn_name weighted_average \
  --debug_visualize_queue_size true