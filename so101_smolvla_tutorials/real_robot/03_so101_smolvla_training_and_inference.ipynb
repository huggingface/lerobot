{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SO101 + SmolVLA è®­ç»ƒå’Œæ¨ç†æ•™ç¨‹\n",
    "\n",
    "æœ¬æ•™ç¨‹åŒ…æ‹¬ï¼š\n",
    "\n",
    "1. âœ… é…ç½®è®­ç»ƒå‚æ•°\n",
    "2. âœ… å¾®è°ƒ SmolVLA æ¨¡å‹\n",
    "3. âœ… ç›‘æ§è®­ç»ƒè¿›åº¦\n",
    "4. âœ… è¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
    "5. âœ… éƒ¨ç½²åˆ°å®ä½“æœºæ¢°è‡‚\n",
    "\n",
    "**å‰ç½®æ¡ä»¶**:\n",
    "- âœ… å·²å®Œæˆæ•°æ®é‡‡é›† (`02_so101_data_collection.ipynb`)\n",
    "- âœ… æ•°æ®é›†å·²ä¸Šä¼ åˆ° Hugging Face Hub\n",
    "- âœ… GPU å¯ç”¨ (æ¨è A100 / RTX 3090)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“¦ æ­¥éª¤ 0: ç¯å¢ƒæ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ” æ£€æŸ¥ç¯å¢ƒ...\")\n",
    "print(\"\")\n",
    "\n",
    "# æ£€æŸ¥ CUDA\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA å¯ç”¨: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    print(f\"GPU æ•°é‡: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU åç§°: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ° GPUï¼Œè®­ç»ƒä¼šéå¸¸æ…¢ï¼\")\n",
    "    print(\"æ¨èä½¿ç”¨ Google Colab æˆ–äº‘ GPU\")\n",
    "\n",
    "print(\"\")\n",
    "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(\"\")\n",
    "\n",
    "# æ£€æŸ¥ LeRobot\n",
    "try:\n",
    "    import lerobot\n",
    "    print(f\"âœ… LeRobot ç‰ˆæœ¬: {lerobot.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"âŒ LeRobot æœªå®‰è£…\")\n",
    "\n",
    "# æ£€æŸ¥ SmolVLA ä¾èµ–\n",
    "try:\n",
    "    from lerobot.policies.smolvla import SmolVLAPolicy\n",
    "    print(\"âœ… SmolVLA å¯ç”¨\")\n",
    "except ImportError:\n",
    "    print(\"âŒ SmolVLA ä¸å¯ç”¨ï¼Œè¯·è¿è¡Œ: pip install -e '.[smolvla]'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âš™ï¸ æ­¥éª¤ 1: é…ç½®è®­ç»ƒå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== åŸºç¡€é…ç½® ==========\n",
    "\n",
    "# Hugging Face ç”¨æˆ·åå’Œæ•°æ®é›†\n",
    "HF_USER = \"your_hf_username\"  # ä¿®æ”¹ä¸ºæ‚¨çš„ç”¨æˆ·å\n",
    "DATASET_NAME = \"my_so101_pickplace\"  # æ‚¨çš„æ•°æ®é›†åç§°\n",
    "DATASET_REPO_ID = f\"{HF_USER}/{DATASET_NAME}\"\n",
    "\n",
    "# ä»»åŠ¡æè¿°ï¼ˆå¿…é¡»ä¸æ•°æ®é‡‡é›†æ—¶ç›¸åŒï¼ï¼‰\n",
    "TASK_DESCRIPTION = \"Pick up the cube and place it on the plate.\"\n",
    "\n",
    "# è®­ç»ƒé…ç½®\n",
    "BATCH_SIZE = 64  # æ ¹æ®æ‚¨çš„ GPU æ˜¾å­˜è°ƒæ•´ (A100: 64, RTX 3090: 32-48)\n",
    "TRAINING_STEPS = 20000  # è®­ç»ƒæ­¥æ•° (çº¦ 4 å°æ—¶ @ A100)\n",
    "LEARNING_RATE = 1e-4  # å­¦ä¹ ç‡\n",
    "\n",
    "# è¾“å‡ºç›®å½•\n",
    "OUTPUT_DIR = Path(\"../models/checkpoints\") / DATASET_NAME\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# æ¨¡å‹åç§°\n",
    "MODEL_NAME = f\"smolvla_{DATASET_NAME}\"\n",
    "\n",
    "# Weights & Biases (å¯é€‰)\n",
    "USE_WANDB = True  # æ˜¯å¦ä½¿ç”¨ W&B ç›‘æ§è®­ç»ƒ\n",
    "WANDB_PROJECT = \"lerobot-so101\"\n",
    "WANDB_RUN_NAME = f\"smolvla_{DATASET_NAME}\"\n",
    "\n",
    "print(\"âœ… è®­ç»ƒé…ç½®ï¼š\")\n",
    "print(f\"  - æ•°æ®é›†: {DATASET_REPO_ID}\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Steps: {TRAINING_STEPS}\")\n",
    "print(f\"  - è¾“å‡ºç›®å½•: {OUTPUT_DIR}\")\n",
    "print(f\"  - W&B: {USE_WANDB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ” æ­¥éª¤ 2: ç™»å½• Hugging Face å’Œ W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç™»å½• Hugging Face\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "print(\"ğŸ” ç™»å½• Hugging Face...\")\n",
    "notebook_login()\n",
    "print(\"âœ… HF ç™»å½•æˆåŠŸï¼\")\n",
    "\n",
    "# ç™»å½• Weights & Biases (å¯é€‰)\n",
    "if USE_WANDB:\n",
    "    import wandb\n",
    "    print(\"\")\n",
    "    print(\"ğŸ” ç™»å½• Weights & Biases...\")\n",
    "    wandb.login()\n",
    "    print(\"âœ… W&B ç™»å½•æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸš€ æ­¥éª¤ 3: å¼€å§‹è®­ç»ƒ\n",
    "\n",
    "### 3.1 æ–¹æ³• 1: ä½¿ç”¨å‘½ä»¤è¡Œè®­ç»ƒ (æ¨è)\n",
    "\n",
    "**ä¼˜ç‚¹**:\n",
    "- æ›´ç¨³å®š\n",
    "- å¯ä»¥åœ¨åå°è¿è¡Œ\n",
    "- ä¾¿äºè°ƒè¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆè®­ç»ƒå‘½ä»¤\n",
    "train_command = f\"\"\"\n",
    "lerobot-train \\\\\n",
    "  --policy.path=lerobot/smolvla_base \\\\\n",
    "  --dataset.repo_id={DATASET_REPO_ID} \\\\\n",
    "  --batch_size={BATCH_SIZE} \\\\\n",
    "  --steps={TRAINING_STEPS} \\\\\n",
    "  --output_dir={OUTPUT_DIR} \\\\\n",
    "  --job_name={MODEL_NAME} \\\\\n",
    "  --policy.device=cuda \\\\\n",
    "  --wandb.enable={str(USE_WANDB).lower()}\n",
    "\"\"\"\n",
    "\n",
    "if USE_WANDB:\n",
    "    train_command += f\" \\\\\n",
    "  --wandb.project={WANDB_PROJECT} \\\\\n",
    "  --wandb.run_name={WANDB_RUN_NAME}\"\n",
    "\n",
    "print(\"ğŸ“‹ è®­ç»ƒå‘½ä»¤ï¼š\")\n",
    "print(\"=\"*70)\n",
    "print(train_command)\n",
    "print(\"=\"*70)\n",
    "print(\"\")\n",
    "print(\"ğŸ’¡ å»ºè®®åœ¨ç»ˆç«¯è¿è¡Œæ­¤å‘½ä»¤ï¼Œä»¥ä¾¿ï¼š\")\n",
    "print(\"  - å®æ—¶æŸ¥çœ‹è®­ç»ƒæ—¥å¿—\")\n",
    "print(\"  - ä½¿ç”¨ tmux/screen åœ¨åå°è¿è¡Œ\")\n",
    "print(\"  - é¿å… Jupyter Notebook è¶…æ—¶\")\n",
    "print(\"\")\n",
    "print(\"ğŸ“Š é¢„è®¡è®­ç»ƒæ—¶é—´ï¼š\")\n",
    "print(f\"  - A100 GPU: ~4 å°æ—¶ ({TRAINING_STEPS} steps)\")\n",
    "print(f\"  - RTX 3090: ~6-8 å°æ—¶\")\n",
    "print(f\"  - CPU: ä¸æ¨è (å¤ªæ…¢)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 æ–¹æ³• 2: åœ¨ Notebook ä¸­è®­ç»ƒ (å®éªŒæ€§)\n",
    "\n",
    "**è­¦å‘Š**: é•¿æ—¶é—´è®­ç»ƒå¯èƒ½å¯¼è‡´ Notebook è¶…æ—¶æˆ–å†…å­˜é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœæ‚¨åšæŒåœ¨ Notebook ä¸­è®­ç»ƒï¼ˆä¸æ¨èï¼‰\n",
    "import subprocess\n",
    "\n",
    "print(\"âš ï¸ åœ¨ Notebook ä¸­å¯åŠ¨è®­ç»ƒ...\")\n",
    "print(\"æç¤ºï¼šä½¿ç”¨ Ctrl+C å¯ä»¥ä¸­æ–­è®­ç»ƒ\")\n",
    "print(\"\")\n",
    "\n",
    "# æ³¨æ„ï¼šè¿™ä¼šé˜»å¡å½“å‰ cell ç›´åˆ°è®­ç»ƒå®Œæˆ\n",
    "# å»ºè®®ä½¿ç”¨ç»ˆç«¯è¿è¡Œ\n",
    "\n",
    "# subprocess.run(train_command.split(), check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š æ­¥éª¤ 4: ç›‘æ§è®­ç»ƒè¿›åº¦\n",
    "\n",
    "### 4.1 æŸ¥çœ‹ W&B Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    print(\"ğŸ“Š Weights & Biases Dashboard:\")\n",
    "    print(\"\")\n",
    "    print(f\"ğŸ”— https://wandb.ai/{HF_USER}/{WANDB_PROJECT}/runs/{WANDB_RUN_NAME}\")\n",
    "    print(\"\")\n",
    "    print(\"åœ¨ Dashboard ä¸­å¯ä»¥æŸ¥çœ‹ï¼š\")\n",
    "    print(\"  - Loss æ›²çº¿\")\n",
    "    print(\"  - Learning rate\")\n",
    "    print(\"  - GPU ä½¿ç”¨ç‡\")\n",
    "    print(\"  - è®­ç»ƒé€Ÿåº¦ (steps/sec)\")\n",
    "else:\n",
    "    print(\"âš ï¸ W&B æœªå¯ç”¨ï¼Œè®­ç»ƒæ—¥å¿—ä»…åœ¨ç»ˆç«¯è¾“å‡º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 æŸ¥çœ‹æœ¬åœ°æ—¥å¿—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹æœ€æ–°çš„è®­ç»ƒæ—¥å¿—\n",
    "log_files = list(OUTPUT_DIR.glob(\"*.log\"))\n",
    "\n",
    "if log_files:\n",
    "    latest_log = sorted(log_files, key=lambda x: x.stat().st_mtime)[-1]\n",
    "    print(f\"ğŸ“„ æœ€æ–°æ—¥å¿—æ–‡ä»¶: {latest_log}\")\n",
    "    print(\"\")\n",
    "    print(\"æœ€å 50 è¡Œï¼š\")\n",
    "    print(\"=\"*70)\n",
    "    with open(latest_log, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[-50:]:\n",
    "            print(line.rstrip())\n",
    "else:\n",
    "    print(\"âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 æŸ¥çœ‹ Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ—å‡ºæ‰€æœ‰ checkpoint\n",
    "checkpoints = sorted(OUTPUT_DIR.glob(\"checkpoint-*\"))\n",
    "\n",
    "print(f\"ğŸ“¦ æ‰¾åˆ° {len(checkpoints)} ä¸ª checkpoint:\")\n",
    "print(\"\")\n",
    "for cp in checkpoints:\n",
    "    # æå– step æ•°\n",
    "    step = cp.name.split(\"-\")[-1]\n",
    "    size_mb = sum(f.stat().st_size for f in cp.rglob('*')) / (1024 * 1024)\n",
    "    print(f\"  - {cp.name} ({size_mb:.1f} MB)\")\n",
    "\n",
    "if checkpoints:\n",
    "    print(\"\")\n",
    "    print(f\"âœ… æœ€æ–° checkpoint: {checkpoints[-1].name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ§ª æ­¥éª¤ 5: åŠ è½½å’Œæµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
    "from lerobot.policies.factory import make_pre_post_processors\n",
    "\n",
    "print(\"ğŸ“¦ åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...\")\n",
    "print(\"\")\n",
    "\n",
    "# é€‰æ‹©æœ€æ–°çš„ checkpoint\n",
    "if checkpoints:\n",
    "    model_path = str(checkpoints[-1])\n",
    "    print(f\"åŠ è½½: {model_path}\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # åŠ è½½æ¨¡å‹\n",
    "    model = SmolVLAPolicy.from_pretrained(model_path)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\n",
    "    print(f\"  - è®¾å¤‡: {device}\")\n",
    "    print(f\"  - å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n",
    "    \n",
    "    # åˆ›å»ºé¢„å¤„ç†å™¨\n",
    "    preprocess, postprocess = make_pre_post_processors(\n",
    "        model.config,\n",
    "        model_path,\n",
    "        preprocessor_overrides={\"device_processor\": {\"device\": str(device)}},\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… é¢„å¤„ç†å™¨åˆ›å»ºæˆåŠŸï¼\")\n",
    "else:\n",
    "    print(\"âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹\")\n",
    "    print(\"è¯·å…ˆå®Œæˆè®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ¤– æ­¥éª¤ 6: éƒ¨ç½²åˆ°å®ä½“æœºæ¢°è‡‚\n",
    "\n",
    "### 6.1 é…ç½®æœºæ¢°è‡‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.robots.so101_follower import SO101Follower, SO101FollowerConfig\n",
    "from lerobot.cameras.opencv import OpenCVCameraConfig\n",
    "from lerobot.datasets.utils import hw_to_dataset_features\n",
    "from lerobot.policies.utils import build_inference_frame, make_robot_action\n",
    "\n",
    "# æœºæ¢°è‡‚é…ç½®ï¼ˆä»æ­¥éª¤ 1 è·å–ï¼‰\n",
    "FOLLOWER_PORT = \"/dev/ttyACM0\"\n",
    "FOLLOWER_ID = \"my_so101_follower\"\n",
    "\n",
    "# æ‘„åƒå¤´é…ç½®ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ç›¸åŒï¼ï¼‰\n",
    "camera_configs = {\n",
    "    \"front\": OpenCVCameraConfig(\n",
    "        index_or_path=0,\n",
    "        width=640,\n",
    "        height=480,\n",
    "        fps=30,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# åˆ›å»ºæœºæ¢°è‡‚å®ä¾‹\n",
    "robot_config = SO101FollowerConfig(\n",
    "    port=FOLLOWER_PORT,\n",
    "    id=FOLLOWER_ID,\n",
    "    cameras=camera_configs,\n",
    ")\n",
    "\n",
    "print(\"âœ… æœºæ¢°è‡‚é…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 è¿æ¥æœºæ¢°è‡‚å¹¶è¿è¡Œæ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"ğŸ¤– å¼€å§‹éƒ¨ç½²...\")\n",
    "print(\"\")\n",
    "\n",
    "# è¿æ¥æœºæ¢°è‡‚\n",
    "robot = SO101Follower(robot_config)\n",
    "robot.connect()\n",
    "\n",
    "print(\"âœ… æœºæ¢°è‡‚å·²è¿æ¥\")\n",
    "print(\"\")\n",
    "\n",
    "# ç‰¹å¾æ˜ å°„\n",
    "action_features = hw_to_dataset_features(robot.action_features, \"action\")\n",
    "obs_features = hw_to_dataset_features(robot.observation_features, \"observation\")\n",
    "dataset_features = {**action_features, **obs_features}\n",
    "\n",
    "# æ¨ç†å‚æ•°\n",
    "MAX_EPISODES = 5  # è¿è¡Œ 5 ä¸ª episode\n",
    "MAX_STEPS_PER_EPISODE = 100  # æ¯ä¸ª episode æœ€å¤š 100 æ­¥\n",
    "\n",
    "print(f\"ğŸ® å¼€å§‹æ¨ç† ({MAX_EPISODES} episodes)...\")\n",
    "print(\"âš ï¸ è¯·ç¡®ä¿å·¥ä½œç©ºé—´å®‰å…¨ï¼\")\n",
    "print(\"\")\n",
    "input(\"æŒ‰ Enter å¼€å§‹...\")\n",
    "\n",
    "try:\n",
    "    for episode in range(MAX_EPISODES):\n",
    "        print(f\"\\nğŸ“ Episode {episode + 1}/{MAX_EPISODES}\")\n",
    "        \n",
    "        for step in range(MAX_STEPS_PER_EPISODE):\n",
    "            # è·å–è§‚æµ‹\n",
    "            obs = robot.get_observation()\n",
    "            \n",
    "            # æ„å»ºæ¨ç†å¸§\n",
    "            obs_frame = build_inference_frame(\n",
    "                observation=obs,\n",
    "                ds_features=dataset_features,\n",
    "                device=device,\n",
    "                task=TASK_DESCRIPTION,\n",
    "                robot_type=\"so101_follower\",\n",
    "            )\n",
    "            \n",
    "            # é¢„å¤„ç†\n",
    "            obs_processed = preprocess(obs_frame)\n",
    "            \n",
    "            # æ¨¡å‹æ¨ç†\n",
    "            with torch.no_grad():\n",
    "                action = model.select_action(obs_processed)\n",
    "            \n",
    "            # åå¤„ç†\n",
    "            action = postprocess(action)\n",
    "            action = make_robot_action(action, dataset_features)\n",
    "            \n",
    "            # å‘é€åŠ¨ä½œ\n",
    "            robot.send_action(action)\n",
    "            \n",
    "            # æ˜¾ç¤ºè¿›åº¦\n",
    "            print(f\"\\rStep {step + 1}/{MAX_STEPS_PER_EPISODE}\", end=\"\", flush=True)\n",
    "            \n",
    "            # æ§åˆ¶é¢‘ç‡\n",
    "            time.sleep(0.033)  # ~30 Hz\n",
    "        \n",
    "        print(\"\\nâœ… Episode å®Œæˆï¼\")\n",
    "        \n",
    "        if episode < MAX_EPISODES - 1:\n",
    "            input(\"æŒ‰ Enter ç»§ç»­ä¸‹ä¸€ä¸ª episode...\")\n",
    "\nexcept KeyboardInterrupt:\n",
    "    print(\"\\nâš ï¸ ç”¨æˆ·ä¸­æ–­\")\n",
    "\nfinally:\n",
    "    # æ–­å¼€è¿æ¥\n",
    "    robot.disconnect()\n",
    "    print(\"\\nâœ… å·²å®‰å…¨æ–­å¼€è¿æ¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“¤ æ­¥éª¤ 7: ä¸Šä¼ æ¨¡å‹åˆ° Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "MODEL_REPO_ID = f\"{HF_USER}/{MODEL_NAME}\"\n",
    "\n",
    "print(f\"ğŸ“¤ ä¸Šä¼ æ¨¡å‹åˆ° Hub: {MODEL_REPO_ID}\")\n",
    "print(\"\")\n",
    "\n",
    "if checkpoints:\n",
    "    try:\n",
    "        # ä¸Šä¼ æœ€æ–°çš„ checkpoint\n",
    "        api = HfApi()\n",
    "        api.upload_folder(\n",
    "            folder_path=str(checkpoints[-1]),\n",
    "            repo_id=MODEL_REPO_ID,\n",
    "            repo_type=\"model\",\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… ä¸Šä¼ æˆåŠŸï¼\")\n",
    "        print(\"\")\n",
    "        print(f\"ğŸ”— æ¨¡å‹é“¾æ¥: https://huggingface.co/{MODEL_REPO_ID}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¸Šä¼ å¤±è´¥: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ æ²¡æœ‰å¯ç”¨çš„ checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… è®­ç»ƒå’Œéƒ¨ç½²å®Œæˆï¼\n",
    "\n",
    "### æ€»ç»“\n",
    "\n",
    "æ‚¨å·²ç»æˆåŠŸå®Œæˆï¼š\n",
    "\n",
    "1. âœ… å¾®è°ƒ SmolVLA æ¨¡å‹\n",
    "2. âœ… ç›‘æ§è®­ç»ƒè¿›åº¦\n",
    "3. âœ… éƒ¨ç½²åˆ°å®ä½“æœºæ¢°è‡‚\n",
    "4. âœ… ä¸Šä¼ æ¨¡å‹åˆ° Hugging Face Hub\n",
    "\n",
    "### æ€§èƒ½ä¼˜åŒ–å»ºè®®\n",
    "\n",
    "å¦‚æœæ¨¡å‹æ€§èƒ½ä¸ç†æƒ³ï¼š\n",
    "\n",
    "1. **é‡‡é›†æ›´å¤šæ•°æ®**ï¼šå¢åŠ åˆ° 100+ episodes\n",
    "2. **å¢åŠ å˜åŒ–**ï¼šæ›´å¤šç‰©ä½“ä½ç½®ã€å§¿æ€å˜åŒ–\n",
    "3. **å»¶é•¿è®­ç»ƒ**ï¼šå¢åŠ åˆ° 40k-50k steps\n",
    "4. **è°ƒæ•´è¶…å‚æ•°**ï¼š\n",
    "   - å­¦ä¹ ç‡ï¼š1e-5 åˆ° 5e-4\n",
    "   - Batch sizeï¼šæ ¹æ® GPU è°ƒæ•´\n",
    "5. **æ•°æ®å¢å¼º**ï¼šæ·»åŠ é¢œè‰²ã€äº®åº¦å˜åŒ–\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "- å°è¯•æ›´å¤æ‚çš„ä»»åŠ¡\n",
    "- å¤šä»»åŠ¡å­¦ä¹ \n",
    "- Sim2Real è¿ç§»\n",
    "- ä¸ç¤¾åŒºåˆ†äº«æ‚¨çš„æ¨¡å‹\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œå®Œæˆæ•´ä¸ªæµç¨‹ï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
