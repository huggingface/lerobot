# Finetune and Use SmolVLA

SmolVLA is Hugging Faceâ€™s compact foundation model for robotics: designed to be easy to finetune on lerobot data, and is great to jumpstart your development!

<p align="center">
  <img src="https://cdn-uploads.huggingface.co/production/uploads/640e21ef3c82bd463ee5a76d/aooU0a3DMtYmy_1IWMaIM.png" alt="SmolVLA architecture." width="500"/>
  <br/>
  <em>Figure 1. SmolVLA takes as input (i) multiple cameras views, (ii) the robotâ€™s current sensorimotor state, and (iii) a natural language instruction, encoded into contextual features used to condition the action expert when generating an action chunk.</em>
</p>

## Setup your environment

First, use the following instructions to properly setup your environment!

```python
git clone https://github.com/huggingface/lerobot.git
cd lerobot

conda create -n smolvlaenv python=3.10 -y
conda activate smolvlaenv
pip install -e ".[smolvla]"
conda install ffmpeg=7.1.1 -c conda-forge # explicitly install the correct version of ffmpeg
```

## Collect a dataset

SmolVLA is a base model, you need to finetune it on your data to use it for your setup.
We recommend starting from [recording a dataset](https://huggingface.co/docs/lerobot/getting_started_real_world_robot#record-a-dataset) of ~50 episodes.

<Tip>

In your dataset, make sure to have enough demonstrations per each variation you are introducing.

We recommend checking out this dataset for reference that was used in the [SmolVLA paper](https://huggingface.co/papers/2506.01844):

ðŸ”— [SVLA SO100 PickPlace](https://huggingface.co/spaces/lerobot/visualize_dataset?path=%2Flerobot%2Fsvla_so100_pickplace%2Fepisode_0)

In this dataset, we recorded 50 episodes across 5 distinct cube positions. For each position, we collected 10 episodes of pick-and-place interactions. This structure, repeating each variation several times, helped the model generalize better. We tried similar dataset with 25 episodes, and it was not enough leading to a bad performance. So, the data quality and quantity is definitely a key!
After you have your dataset available on the Hub, you are good to go to use our finetuning script to adapt SmolVLA to your application!
</Tip>

## Finetune SmolVLA on your data

Use [`smolvla_base`](https://hf.co/lerobot/smolvla_base), our pretrained 450M model, and fine-tune it on your data!
Training the model for 20k steps will roughly take ~3hrs on a single A100 GPU. You should tune the number of steps based on performance and your use-case.

Pass your dataset to the training script using `--dataset.repo_id`. If you want to test your installation, run the following command where we use one of the datasets we collected for the [SmolVLA Paper](https://huggingface.co/papers/2506.01844).

```python
# Note: Path to the model to finetune: --policy.path
# Note: Change dataset to your HF_USER/DATASET_NAME: --dataset.repo_id
python lerobot/scripts/train.py \
  --policy.path=lerobot/smolvla_base \
  --dataset.repo_id=lerobot/svla_so100_stacking \
  --batch_size=64 \
  --steps=20000  # trains for 10% of our total training budget for adaptation to your usecase
```

<Tip>
You can start with a small batch size and increase it incrementally, GPU permitting, as long as loading times remain short.
</Tip>

Again, there is no perfect recipe for the finetuning.

For a complete overview of the options for finetuning, run
```
python lerobot/scripts/train.py --help
```

<p align="center">
  <img src="https://cdn-uploads.huggingface.co/production/uploads/640e21ef3c82bd463ee5a76d/S-3vvVCulChREwHDkquoc.gif" alt="Comparison of SmolVLA across task variations." width="500"/>
  <br/>
  <em>Figure 2: Comparison of SmolVLA across task variations. From left to right: (1) pick-place cube counting, (2) pick-place cube counting, (3) pick-place cube counting under perturbations, and (4) generalization on pick-and-place of the lego block with real-world SO101.</em>
</p>


## Evaluate the pretrained policy and run it in real-time

Record the evaluation process and save your evaluation to the hub by running:

```python
huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential
```

Store your **Hugging Face User Name** in a variable to run these commands:

```python
HF_USER=$(huggingface-cli whoami | head -n 1)
echo $HF_USER
```

Now, indicate the path to the policy, `policy.path`, which is `lerobot/smolvla_base` in this case, and run:

```python

python -m lerobot.record \
  --robot.type=so101_follower \
  --robot.port=/dev/tty.usbmodem58760431541 \
  --robot.id=my_blue_follower_arm \
  --teleop.type=so101_leader \
  --teleop.port=/dev/tty.usbmodem58FA1015821 \
  --teleop.id=my_blue_leader_arm \
  --dataset.fps=30 \
  --dataset.single_task="Grasp a lego block and put it in the bin." \
  --dataset.repo_id=${HF_USER}/eval_svla_base_test \  # <-- Note: this will be the dataset name on HF Hub!
  --dataset.tags='["tutorial"]' \
  --dataset.episode_time_s=30 \
  --dataset.reset_time_s=30 \
  --dataset.num_episodes=10 \
  --dataset.push_to_hub=true \
  --policy.path=lerobot/smolvla_base

```
Depending on your evaluation setup, you can configure the duration and the number of episodes to record for your evaluation suite.
